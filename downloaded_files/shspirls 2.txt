U.S. Department of Justice
Office of Justice Programs
Bureau of Justice Statistics
A BJS Internet Document 

Summary of Human Subjects Protection Issues
Related to Large Sample Surveys

June 2001, NCJ 187692

----------------------------------------------

The full formatted report is available
in .pdf format at- 
<http://www.ojp.usdoj.gov/bjs/abstract/shspirls.htm>

----------------------------------------------

By
Joan E. Sieber



U.S. Department of Justice
Office of Justice Programs
John Ashcroft
Attorney General

Bureau of Justice Statistics
Lawrence A. Greenfeld
Acting Director

Report of work performed under a BJS purchase
order to Joan E. Sieber, Department of
Psychology, California State University at
Hayward, Hayward, California 94542, (510) 538-
5424, e-mail jsieber@csuhayward.edu.  

The author acknowledges the assistance of
Caroline Wolf Harlow, BJS Statistician and
project monitor.  Ellen Goldberg edited the
document.

Contents of this report do not necessarily
reflect the views or policies of the Bureau of
Justice Statistics or the Department of Justice.

This report and others from the Bureau of
Justice Statistics are available through the
Internet   <http://www.ojp.usdoj.gov/bjs>

Table of Contents

1.  Introduction
Limitations of the Common Rule with respect to
survey research

2.  Risks and benefits of participation in
sample surveys
Standard risk issues, researcher responses, and
IRB requirements
Long-term consequences
Background issues

3.  Procedures to protect privacy and maintain
confidentiality
Standard issues and problems
Confidentiality assurances and their
consequences
Emerging issues of privacy and confidentiality

4.  Other procedures for minimizing risks and
promoting benefits
Identifying and minimizing risks
Identifying and maximizing possible benefits
5.  Procedures for responding to requests for
help or assistance
Standard procedures
Background considerations
A specific recommendation: An experiment within
the survey

6.  Procedures for responding to mandates to
report
Child maltreatment
Elder abuse
Intent to harm oneself or others

7.  Vulnerable populations: Risks and special
protections
IRB concerns
Children and teenagers
Pregnant women
Cognitively impaired persons
Elderly persons
Minorities
Students, employees, and institutionalized
persons
Economically or educationally disadvantaged
persons

8.  Efforts to minimize refusals to participate
in sensitive survey
Efforts to induce participation
Efforts to evoke answers to sensitive questions

9.  Survey procedures for informed consent with
special procedures for obtaining consent for
respondents under age 18
Regulatory requirements
Informed consent as practiced in survey research
     
10.  Effects of signed consent on response rates
and other aspects of conducting a survey or
other study
Regulatory issues
Background considerations

11.  Researching ethical questions
The experiment within a study
The focus group
Ethnography    
Meta-communication in the research process

12.  Keeping abreast of new developments and
answering questions 
On-line resources   
Meetings  
Journals  
Informal local groups    
Office of Human Research Protections 
   
13.  Briefly annotated bibliography of
literature cited

Appendix A.  State phone numbers for reporting
child maltreatment

Appendix B.  Using focus groups

This report identifies best practices to ensure
that large sample surveys such as the National
Crime Victimization Survey (NCVS) are ethically
sound and compliant with the Common Rule.  There
are three approaches used in this report to
identify best practices:

*Identify regulations and statutes governing
each question, and the position of the Office of
Human Research Protections (OHRP) and of major
Institutional Review Boards (IRBs) and
investigators who oversee large sample survey
research.   
*Recognize that these are general guidelines. 
Federal regulations recognize that broad areas
of investigator and IRB discretion are required
to validly investigate sensitive topics.  The
IRB's mandatory reasoned discussion and
decision-making must be based on a broad
understanding of the issues, and the IRB must
document its decision process in its minutes.
*Provide resources that would enable the Bureau
of Justice Statistics (BJS) to increase its
sophistication and to evolve as issues change
with new regulatory requirements and
interpretations and with changes in the
country's social or political environment.  

This report addresses the following nine issues:

*The risks and benefits of participating in
sample surveys on sensitive topics.
*Procedures to protect respondent privacy and
ensure the confidentiality of data. 
*Procedures to minimize risks and promote
benefits to respondents.
*Procedures to respond to requests for help or
assistance.
*Procedures to respond to revelations of a
situation that interviewers must, by statute,
report to appropriate authorities.
*Dangers and safeguards for vulnerable
populations, including children and teenagers,
pregnant women, mentally disabled persons, and
persons confined to an institution, particularly
correctional facilities.
*Efforts to minimize refusals to participate in
surveys concerned with sensitive topics.
*Survey procedures for informed consent; special
procedures for obtaining consent for respondents
under age 18.
*Effects of signed consent forms on response
rates and other aspects of conducting a survey
or other study

1.  Introduction 

The NCVS, sponsored by the Bureau of Justice
Statistics (BJS), is conducted and analyzed by
the U.S. Census Bureau which then provides
summary statistics and data files to BJS.  This
survey asks sensitive questions of the same set
of respondents every 6 months over 3 years
(seven times); respondents include all members
of a given household who are at least age 12. 
Over 40,000 households or living groups are
surveyed.  This research is exempt from IRB
review and from the Common Rule (45 CFR 46,
subpart A).  However because the NCVS involves
complex ethical issues, BJS has requested this
review of issues pertinent to the ethics and
regulatory requirements of large-scale sample
surveys that ask sensitive questions and study
vulnerable populations.   

The federal policy for the protection of human
subjects, which formerly pertained only to
Health and Human Services research (45 CFR 46,
Subpart A), has now been incorporated into the
regulatory structure of 17 federal agencies,
eight of which have additional human subject
protections. ***Footnote 1.  These agencies and
their relevant regulations are: Housing and
Urban Development (24 CFR 60), Justice (28 CFR
46 with additional protections in 28 CFR 512 and
28 CFR Part 22), Transportation (49 CFR 11),
Veterans Affairs (38 CFR 16 with additional
protections in 38 CFR 17.85, M-3, Part 1,
Chapters 9 and 15), Consumer Product Safety (16
CFR 1028), Environmental Protection (40 CFR 26),
International Development (11 CFR 225), NASA (14
CFR 1230), NSF (46 CFR 690), Agriculture (7 CFR
16), Commerce (15 CFR 27), Defense (32 CFR 219,
plus 12 additional regulatory protections),
Education (with extensive additional protections
to privacy and confidentiality as noted below),
Energy (10 CFR 745), Health and Human Services
(45 CFR 46 Subpart A), Social Security (P.I.
103-296), and CIA (Executive Order 12333); the
last three agencies also employ Subparts B, C,
and D of 45 CFR 46.*** Subpart A, which is now
known as the Common Rule, as well as the rest of
45 CFR 46 (Subparts B, C, and D), may be found
at <http://ohrp.osophs.dhhs.gov/ >under Policy
Guidance.  Briefly, the Common Rule sets forth
the role and operation of the IRB, the required
elements of the research protocol and the
informed consent, and general criteria for IRB
review and approval.  The Department of Justice
regulation is found at 28 CFR Part 46.

Limitations of the Common Rule with respect to
survey research

The Common Rule poorly defines privacy and
confidentiality in survey research.  It promotes
the prevalent misconception that self-report
research is necessarily less risky than
experimental or observational research.  For
example, it exempts anonymous surveys of adults
from IRB review (45 CFR 46.101(b)(2)), on the
premise that adults can freely protect their
privacy by refusing to answer.  In fact, self-
report questions can induce respondents to
reveal far more personal and sensitive aspects
of their lives than can be studied ethically by
observational or experimental methods (see
section 2).  Subjects should at least give
informed consent based on an accurate
understanding of the kinds of questions that
will be asked.

The Common Rule specifically requires that
informed consent include a statement about how
the researcher will maintain confidentiality. 
However it leaves to the IRB and the researcher
the subtle matter of understanding what
confidentiality is and how it relates to
privacy.  The Common Rule defines privacy
obliquely by reference to private information,
as follows:

Private information includes information about
behavior that occurs in a context in which an
individual can reasonably expect that no
observation or recording is taking place, and
information which has been provided for specific
purposes by an individual and which the
individual can reasonably expect will not be
made public (for example, a medical record). 
(45 CFR 46.102(f)(2))

This oblique reference to privacy confuses it
with confidentiality (an understanding or
agreement about the disclosure or nondisclosure
of identifiable information to others) and fails
to convey the notions of personal privacy
(discussed in section 3) that are important to
ethical research.  It also implies that everyone
has the same concerns about others' access to
themselves and to identifiable data about
themselves, and that researchers and IRBs can
accurately assess what others situated
differently from themselves would consider as
private.
Based on this confusing set of definitions, the
Common Rule states that:
(7) When appropriate, there are adequate
provisions to protect the privacy of subjects
and to maintain the confidentiality of data. 
(45 CFR 46.111(a)(7))
Unfortunately, this requirement assumes a level
of sophisticated knowledge concerning privacy
and confidentiality that most IRBs and
researchers do not possess.   
Given these limitations of the Common Rule, the
conscientious survey researcher might look
beyond the Common Rule to Subparts B, C, or D of
45 CFR 46 for guidance.  Subpart B pertains to
biomedical research on fetuses, pregnant women,
and human in vitro fertilization, and Subpart C
pertains to persons under correctional
supervision.  Neither of these sections are
relevant to the NCVS.  However Subpart D
pertains to minors and is sensitive to
children's personal privacy interests.  It
requires the child's active assent (when assent
would be meaningful) and parental permission,
with either party having veto power.  It
recognizes that there are contexts in which
parental permission is not a reasonable
requirement to protect the subjects (such as
neglected or abused children), and also
recognizes a range of circumstances in which
parental permission may be waived.  The parental
permission requirement respects the parents'
right to control the conditions of their child's
life and their ability to judge the degree of
acceptable risk for their child to take. 
Subpart D requires IRB approval when the
research involves minors and anonymous surveys,
interviews, and observation of public behavior
in which the investigator participates in the
activities being observed.  It limits a child's
exposure to risk, even if there is parental
permission and the child's assent.
2.  Risks and benefits of participation in
sample surveys

Risks to privacy and confidentiality have long
been deemed the main risks in sample survey
research.  However the scope and magnitude of
this risk has increased as more sensitive topics
are studied, and as researchers begin to
oversample vulnerable and marginalized
populations.  As Bersoff and Bersoff (2000)
point out, surveys raise issues of privacy that
are rarely found in other research.  There is
the potential for self-report research to glean
clinically sensitive data and put it in the
hands of non-clinicians.  Even if the survey is
anonymous, researchers should not ignore the
potential for violation of confidentiality and
for severe emotional upset to respondents.

Standard risk issues, researcher responses, and
IRB requirements

To prepare a research project for review by an
IRB, researchers must provide appropriate
discussion of risks and benefits in the protocol
and in the informed consent documentation.  The
IRB is required to evaluate the adequacy of
researchers' recognition of potential risk and
benefit, their plans for reducing or preventing
risk and enhancing benefit, and the
appropriateness with which this information is
presented in the informed consent.   

The risks that can arise in survey research are
the same basic risks that can arise in other
research:

*Mere inconvenience when a survey is
administered at an inconvenient time or place or
simply takes too long to administer.
*Emotional or psychological risk when a survey
causes upset, or worry, warranted or not, about
breach of confidentiality.
*Social risk due to stigma or other negative
social outcomes of breach of confidentiality.
*Physical risk if revelations about others get
back to those persons, particularly when
researchers study domestic violence, gang
activity, or other phenomena concerning
violence-prone individuals.
*Financial risk if revelations result in loss of
employment or insurance coverage.
*Legal risk when illegal activities are
disclosed

Most researchers do not catalog every
conceivable risk in their consent document or in
their protocol, nor do IRBs expect them to do
so.  However IRBs are mindful of the risks that
researchers may overlook, including those
described above.  Most of the risks have to do
with breach of confidentiality or fear or worry
about a possible breach.  The IRB is likely to
want to know specifically how confidentiality is
handled, whether limits to confidentiality are
adequately disclosed, and whether promises of
confidentiality can actually be guaranteed. 
IRBs are attuned to issues of "secondary
subjects," who are identifiable persons about
whom the respondent is asked sensitive
questions.  These "secondary subjects" are
considered subjects of survey research because
they are identified and researchers obtain
information about them.  If feasible,
investigators should obtain their informed
consent as they too may be placed at risk.  If
it is deemed impractical or impossible to obtain
their informed consent, the waiver of informed
consent should meet the requirements specified
in the Common Rule, and the IRB must document
its discussion and decision in its minutes.   

Long-term consequences

A sensitive matter is usually a troubling one. 
It may be a matter the respondent fears to
discuss lest others learn about their particular
situation.  Fears of social or economic
reprisals can cause respondents to lie, refuse
to answer, or answer honestly but worry for a
long time afterward.  IRBs should recognize the
importance of accurately identifying the kinds
of unwarranted fears respondents are likely to
have, as well as the actual risks.  They require
investigators to take steps to reduce both kinds
of fears, and to ensure that researchers can
keep promises of confidentiality.   

Some matters are so sensitive that the
respondent may relive it when discussing it. 
For example events such as physical assault are
so traumatic that the respondent would
reexperience old pain by retelling the details
yet again.  IRBs customarily require that
researchers who inquire about sensitive issues
such as rape have referral information and even
availability of several free therapy sessions
for respondents who recount traumatic events and
would welcome such assistance in restoring their
emotional well being.

The benefits to respondents of participation in
surveys (not to be confused with financial
incentives, which are discussed in section 8)
are usually limited to the benefits of an
interesting exploration of some topic, an
informative and satisfying exchange in the
debriefing process, and some written information
pertinent to the topics discussed.  (See section
4 for other appropriate and feasible additional
benefits.)   

Depending on the particular survey, the IRB will
question whether vulnerable populations, non-
English speakers, children, and persons whose
autonomy is somehow constrained are accorded due
protection and respect.  These issues are
discussed in section 7.

Background issues

As most skilled interviewers have learned,
getting in the door to interview an individual
is not as hard as getting out.  A well-
constructed survey and a skilled interviewer can
create powerful motivation to discuss personal
matters.  This is a source of both benefit and
risk, especially with repeated-measure surveys
(such as the NCVS) in which a relationship is
built up over time.  Properly constructed
surveys begin with easy, non-threatening
questions.  Each new topic is initiated with a
general, non-threatening question and followed
by increasingly specific and sometimes more
sensitive questions.  This funneling from
general to specific makes for easy recall of
related information, good comprehension of
related questions, and rapid responding.  It
also makes respondents comfortable with
questions they otherwise would refuse to answer. 
Lonely or troubled respondents are especially
likely to welcome the attention of a respectful
and skilled interviewer who promises
confidentiality.   
Respondents may find the interview session
interesting, and perhaps even a therapeutic
opportunity to recall and reflect upon their
experiences or to get some things "off their
chest."  The ethical and well-prepared
interviewer is a good listener and keeps private
information confidential.  In response to a
request for help or to signs of problems, or
simply as a routine part of debriefing, the
interviewer may provide useful feedback,
referrals, or reference materials.

It would seem apparent that the respondent can
readily refuse to answer any question that is
too personal.  Answering a question seems
tantamount to informed consent, hence it is
often assumed that there is little risk
involved.  This assumption of respondent
autonomy and ease of refusing to answer
questions is somewhat illusory given what is
known about the "foot in the door" technique
(Freedman and Fraser, 1966).  Once persons agree
to a small and benign request, they can be
gotten to agree to a larger and less benign
request which they would ordinarily never agree
to, or to which persons who did not receive the
first benign request would not agree. 
Interviewers can lead respondents who would
ordinarily refuse to answer highly personal or
embarrassing questions about some aspect of
their personal life to answer such questions by
first asking them to answer a rather tame
question on the same topic.  The underlying
principle is that people want to appear
consistent and cooperative and hence will
continue to answer questions even when they
would otherwise judge it ill-advised to do so
(Cialdini, 1993; Orne, 1962).   

The power of the well-constructed survey to
yield answers to sensitive questions is a good
thing in the hands of an ethical, sensitive,
well-trained interviewer, but it can be
dangerous otherwise.  There are several possibly
serious risks.  Details of some of these risks
and associated risk prevention strategies are
discussed in subsequent sections.  Respondents
may: 

*reveal reportable criminal activities, 
*reveal information damaging to their social or
financial standing, employability, or reputation
which the researcher fails to treat as
confidential,
*reveal information that is treated with
appropriate confidentiality but which
nevertheless causes the respondent to worry
about the confidentiality of the disclosure or
to feel embarrassed,
*reach out for help such as by revealing
suicidal ideation to an insensitive interviewer
whose inappropriate response confirms the
respondent's sense of hopelessness,
*reach out for help but then feel betrayed or
embarrassed that the interviewer took stronger
action than was expected,
*recall and ruminate about unresolved issues
that the interviewer fails to recognize or
respond to appropriately,
*reveal information in a family, community, or
organizational setting where their privacy or
the privacy of others in that group is not
accorded due respect, or reveal potentially
damaging information about another identified
person (the secondary subject), 
*respond to emotionally charged topics that may
cause them to focus long afterward on painful
memories such as brutal crime victimization, or 
*experiment with socially unacceptable behavior
in response to an interviewer who uses the
"everybody does it" approach to evoking answers
about unacceptable behavior. 

The appropriate safeguard is not to weaken the
power of the survey to gather information, but
to strengthen the protections offered.  The IRB
frequently identifies the possible risks, and
helps the researcher become sensitive to
possible signs of risk and to plan appropriate
safeguards.  

In addition to safeguards to confidentiality,
investigators should consider how to conclude
the interview.  The respondent should have an
opportunity to express reactions or ask
questions.  The conclusion should be a two-way
conversation and should not be carried out in a
perfunctory manner.  It should adequately settle
any questions or concerns the respondent may
have, and return the respondent to a positive,
satisfied state of mind.

Many interviewers are unprepared for risks even
after they are sensitized to their possible
occurrence.  Researchers should develop referral
and feedback information that might be generally
useful to all respondents.  They should also
locate institutional or outside resources that
can respond appropriately to respondents  who
reach out for help or indicate distress.  There
should be competent professionals who are
available to researchers for consultation when
issues arise which the researcher (interviewer)
feels unprepared to handle.  However the
investigators must always respect the wishes of
the respondent and keep promised conditions of
confidentiality.  Giving more help than is
wanted is often harmful, not helpful.  Moreover
the interviewer should not attempt to help
beyond providing referrals or other written
resource information.  These topics are
discussed further in sections 3 through 7.3. 
Procedures to protect privacy and maintain
confidentiality 

The Common Rule and most guidelines for IRBs
emphasize the importance of privacy and
confidentiality but are neither specific nor
detailed in their recommendations.  There is a
superb literature on approaches to respecting
privacy and confidentiality with which survey
researchers should be familiar.

Standard issues and problems

The Common Rule leaves much to the judgment of
IRBs with respect to privacy and
confidentiality, so that the same degree of
caution need not be imposed on all research.  45
CFR 46.111 (a)(1) states that "Risks to subjects
are minimized: (i) By using procedures which are
consistent with sound research design, and which
do not unnecessarily expose subject to risk,"
and 45 CRF 46.111(a)(7) states that "When
appropriate, there are adequate provisions to
protect the privacy of subjects and to maintain
the confidentiality of data."  

How do IRBs identify the relevant issues? 
Invasion of personal privacy is a subjective
matter, and IRB members judge invasion of
privacy on their own sense of propriety and on
the particular circumstances of the study.  This
can be an inadequate basis for judgment.
Confidentiality is an objective but complex
matter and involves many possible judgments
depending on the research.  Confidentiality
pertains to data on identifiable persons.  In
recent times, IRBs have become increasingly
concerned about what constitutes an identifiable
respondent of survey research.  When is a survey
truly anonymous?  Even when the names of
respondents are never attached to their data,
there is increasing concern about deductive
identification of otherwise anonymous
respondents on the basis of such elements of
their data as birth date, occupation, zip code,
race, and gender.  The issue of an "identifiable
subject" also arises if the researcher wants
access to existing records to identify persons
suitable for the proposed study; if the data
being sought are sensitive, the IRB may judge
that consent of subjects should be obtained for
accessing those existing data.  If existing
school data are sought on youngsters, the
Buckley Amendment (the General Education
Provisions Act (20 USC 1232)) requires parental
permission for release of identifiable
information about children in public schools.  

IRBs do not consider sample survey research
anonymous (and hence exempt from IRB review) if
identifiers that accompany the data are later
stripped from the data.  If a unique identifier
was attached to it at some point in the process
-- for purposes of respondent selection and
interviewing or for recontacting selected
subjects by a supervisor checking on the work of
the interviewer -- it is not an anonymous
survey.  A survey that involves any identifiable
data at any point in the research process is
subject to IRB review.

If researchers are collecting sensitive survey
data about identified individuals, the IRB will
inquire whether there are provisions for
protecting the confidentiality of the data. 
Such provisions typically include substituting
codes for identifiers and storing the code key
elsewhere, removing face sheets (typically
containing such information as names, phone
numbers, or addresses), destruction of
identifying information such as computer sheets,
keeping data in locked files, impressing on
research assistants the importance of
confidentiality, and limiting access to the data
by various means.  Data from large sample
surveys are normally stored electronically for
easy access and analysis.  Whenever identifiers
accompany these data or when deductive
identification would be easy, there is major
concern about the security of the computer
system on which the data are stored, and
researchers must satisfy these concerns.

A particularly difficult issue has to do with
the training and supervision of interviewers and
research assistants.  Where possible, the
research staff should not be persons who might
know some of the respondents, though this is
difficult to ensure.  Researchers who are
concerned about the cultural and linguistic
matching of interviewers with subject
populations should consider hiring and training
local people.  However, there is the risk that
the interviewer will know the respondent.   

The Common Rule defines and discusses privacy
and confidentiality in ways more appropriate to
biomedical research than to survey research.  It
fails to recognize both the aspects of personal
privacy that the effective interviewer must
respect and the individual subjectivity and
diversity of people's sense of privacy.  With
respect to confidentiality, it gives no hint of
the vast technical literature on methods of
ensuring confidentiality in survey research.

Privacy

The difficulty of defining invasion of one's own
privacy is evocatively expressed by Melton
(1992, p. 66):

'I know it when I feel it.'  A gut sense of
personal violation may be the tie that binds
such disparate events as being subjected to a
body search, being the subject of gossip, having
one's mail read, being asked one's income, or
having one's house entered without permission. 
It should come as no surprise that such an
intensely personal construct is difficult to
define.

It is difficult to define, understand, and
respect the privacy of other persons situated
differently from ourselves.  Without a useful
definition or theory of privacy to guide them,
researchers and IRBs must depend on their own
culture-bound notions of privacy.  They invoke
their personal and idiosyncratic definitions,
resulting in a capricious standard of
protection.  
The meaning of privacy in survey research
inheres in the culture and personal
circumstances of the particular subject, the
context and nature of the research, and the
social and political environment in which the
research occurs.  A useful definition of privacy
that recognizes these manifold elements is
borrowed from, and based on, the elegant theory
of personal privacy developed by Laufer and
Wolfe (1977):

Privacy refers to persons and to their interest
in controlling the access of others to
themselves.

This theory of personal privacy recognizes the
manifold cultural, developmental, and
situational elements by which individuals
orchestrate their privacy.  It recognizes that
people have an interest in (a) controlling the
time, place, and nature of the information they
give to others, and (b) controlling the
information or experiences that are proffered to
them.  Thus informed consent serves as a control
mechanism, provided the prospective subjects of
survey research are adequately informed of what
it is they will be asked and what they may
experience.   

Laufer and Wolfe's theory would be highly useful
to efforts to educate IRBs; to design ethical
elements of recruitment, consent, location,
circumstances, and content of surveys; and to
train interviewers.  Laufer and Wolfe's theory
embodies four dimensions of privacy:

The self-ego dimension refers to the development
of autonomy and personal dignity.  Young
children have an aversion to being alone.  By
middle childhood, children seek time alone to
establish a sense of self and to nurture new
ideas, creating a basis for self-esteem,
personal strength, and dignity.  By age 6 or 7,
children have a need and right to privacy not
found in infants and younger children. 
Teenagers are intensely private, as they seek to
forge an identity separate from that of their
parents.  Teenagers would be embarrassed  to be
interviewed about personal matters in the
presence of their parents or others, and in the
presence of their parents would most likely
refuse to be interviewed or lie in their
answers.  Adults continue to need time alone and
develop many means of protecting that privacy.  

The environmental dimension includes socio-
physical, cultural, and life-cycle dimensions. 
Socio-physical elements are physical or
technological elements that offer privacy; more
affluent individuals tend to have more of such
barriers to unwanted intrusion.  Cultural
elements include norms for achieving privacy;
for example some cultures permit lying while
others  permit persons to have private rooms and
telephones.  Life-cycle elements vary with age,
occupation, available technology, and changing
socio-cultural patterns.  The ways one
establishes privacy at one age, under one set of
circumstances, may be unsatisfactory or
unavailable at a later stage.

The interpersonal dimension refers to how
interaction and information are managed.  One's
social setting and its physical characteristics
provide options for managing social interaction;
physical and social boundaries can be used to
control people's access to one another.

The control/choice dimension grows out of the
other dimensions.  Young children have no
control over their privacy except through
hiding.  They learn to use personal, cultural,
and physical resources to control their privacy. 
Events that would threaten one's privacy early
in the development of control/choice are later
so easy to control that they are no longer
considered a threat to privacy.

Understanding and respecting the privacy of
others

How do the researcher and IRB learn about the
privacy interests of persons situated
differently from themselves?  Networks of local
researchers, educators and outreach workers such
as social workers, farm agents, and public
health nurses can share valuable information
about the most appropriate ways to approach
members of various cultures.  Interviewers who
are of the same culture and backgrounds are
vital to some sensitive research in some kinds
of communities.  Focus groups and other forms of
community consultation are useful ways to learn
about a culture, how the individuals within that
community perceive the research, and how the
research that would be objectionable to them can
be made acceptable.  The community meetings held
by Fisher and Wallace (2000) are a good example
of learning the views and suspicions of members
of inner-city African Americans about studies of
adolescent risk behavior.  The community
consultation discussed in Melton et al. (1988)
is a dramatic example of the explosive
acquaintance process of AIDS activists with AZT
researchers.  While only the Fisher and Wallace
account focuses on survey research, there is
much that survey researchers could learn from
both accounts about the importance of
understanding the perspective of one's subjects
in field-based applied research.

Community consultation can also ameliorate fears
among potential respondents who feel a need to
avoid strangers.  For example, a large-scale
survey of the housing needs of the elderly
required that interviewers go to the homes of
elderly people, who are fearful of scam artists,
robbers, and burglars.  The interview teams
began by making well-advertised visits to senior
centers in the neighborhoods where they would be
conducting their survey.  They explained their
project, answered questions, and made certain
that the local newspaper carried the story of
their presentation and project, along with
photographs of them.  Their first contact with
their prospective respondents was by letter, and
it included a copy of the newspaper article with
the pictures of the interviewers.  The
interviewers then phoned to make an appointment
for their visit.  When they appeared at the
door, they carried with them a copy of the
newspaper article so that the respondents could
see that they were indeed the designated
interviewers. 

Confidentiality

The following definition of confidentiality is
adapted from that developed by Boruch and Cecil
(1979):

Confidentiality is an extension of the concept
of privacy; it refers to (a) identifiable data
(some information about a person that would
permit others to identify the specific person,
such as a non-anonymous survey, notes or a
videotape of the person) and (b) agreements
about how those data are to be handled in
keeping with respondents' interest in
controlling the access of others to information
about themselves.

The two critical elements of this definition  
identifiable data and agreement about the
handling of the data   indicate the critical
role of informed consent, which states how the
researcher will control access to the data and
secures the respondent's agreement to
participate under these conditions.  This
definition further underlines the importance of
planning before gathering sensitive data.  It is
important that researchers make early plans
regarding techniques to ensure confidentiality. 
They should incorporate these plans into the
methodology and into any consent agreements with
respondents or contractual agreements with
subsequent users of the data, including funders
who may wish to audit the data.  Investigators
should include all of these details in the IRB
protocol.

This definition of confidentiality leads
naturally to the literature on procedural,
methodological, statistical, and legal
approaches to ensuring the confidentiality of
survey research data.  

Methods and procedures of ensuring
confidentiality****Footnote: Portions of this
section are drawn from an unpublished paper that
was commissioned by the National Bioethics
Advisory Commission:  J. E. Sieber, Privacy and
Confidentiality: As Related to Human Research in
Social and Behavioral Science, 2000.***

Approaches to ensuring confidentiality of survey
research fall into seven categories:
* Procedures that eliminate linkage of data to
unique identifiers 
*Intersystem linkage
*Statistical strategies
*Agreements: Data sharing, secondary analysis,
or audit of data
*Legal protections
*Descriptive statistics and raw data releases
*Internet research

Procedures that eliminate linkage of data to
unique identifiers.  Anonymity offers the best
insurance that disclosure of subjects' responses
will not occur.  Researchers have developed
dozens of techniques that are responsive both to
the need for anonymity and to other research
needs.  Different kinds of data   cross-
sectional, longitudinal, and data from multiple
sources   bring with them different research
requirements and different ways of meeting those
without using unique identifiers of subjects. 
The following brief summary is illustrative, not
comprehensive.  See Boruch and Cecil (1979) for
a comprehensive review.

Cross-sectional surveys, in their simplest form,
require just one data collection session. 
Anonymity in which even the researcher is at all
times ignorant to the identity of subjects
protects the respondent from legal prosecution,
social embarrassment, and concern that the data
may fall into the wrong hands.  However it may
be desirable to have some form of follow-up to
test for sampling validity, response validity,
or to do further research on some or all
subjects.  These refinements are impossible with
complete anonymity, but can be achieved through
temporarily identified responses with subsequent
destruction of identifiers, or through use of
brokers to provide anonymous data to the
researcher after completing one or more of these
refinements.

Longitudinal surveys track individual subjects
over time.  There are many ways in which aliases
or arbitrary identifiers can be used as a basis
for linking observations over time while
preserving the confidentiality of individual
responses.  For example, subjects may choose an
easily remembered alias and use it on repeated
occasions.  Some approaches are quite complex. 
For example, research by the American Council on
Education (Austin and Boruch, 1970) on political
activism among American college students used
the following three-file linkage system:

1.  Initial data collection:
* File A contains each subjects' data and
arbitrary account number (X).  
*File B pairs each subject's name with a second
arbitrary account number (Y).  File C matches
the two sets of account numbers, X and Y.
*File C is shipped to a researcher in a foreign
country
2.  Second data collection:
* Second set of identifiable longitudinal data
are gathered.
* Names are replaced by their Y account number;
this file is shipped to the foreign researcher.

3.  Data analysis:
* Foreign researcher substitutes X account
numbers with corresponding Y numbers.  
* Each set of data files is returned to the data
analysts.
* Data are organized in longitudinal sequences;
the identity of each subject is unknown.
* The longitudinal data are analyzed.
* Foreign researcher destroys File C; the three
files can never be merged to learn subject
identities.

Thus the data were safe.  Conceivably, foreign
discovery procedures could be used to obtain
some of the identifiable data before File C is
destroyed.  Therefore a Certificate of
Confidentiality (see below) could be obtained to
preclude that unlikely event.
Intersystem linkage.  Intersystem linkage is
sometimes necessary to link research records on
subjects with other, independently stored
records on the same individuals.  In the case of
highly sensitive data such as psychiatric or
police records, a linkage strategy may be needed
so that the researcher does not have access to
any identified records.  

One such method is as follows:

1.  Researcher wishes to link data on 50
subjects with information from their police
records.
2.  Subject provides data and an alias (no name)
to the researcher.
3.  Subject provides to the archive (police) his
name and alias.
4.  Archive provides the requested police
information with the aliases (not the names)
attached
5.  Researcher analyzes relationship between his
research data and the police record data.

This brief summary is merely illustrative of
some of the many specific procedures for
preserving anonymity or confidentiality.  The
actual literature on this topic is immense. 
(See Boruch and Cecil (1979), and Campbell,
Boruch, Schwartz, and Steinberg (1977).  See
also current U.S. Census Bureau papers on this
topic.)
Statistical strategies.  Researchers have
developed various statistical strategies to
eliminate any direct link between the
respondent's identity and his true answer.  All
of these methods involve the injection of a
specified amount of random error into the
dataset so that researchers cannot ascertain an
individual's true identity but can still perform
a useful statistical analysis of the data.  

The statistically elegant randomized response
method is used in direct interview to protect
privacy and to ensure confidentiality.  The
following is an oversimplified example:  Suppose
the researcher wished to ask whether respondents
had struck their child in anger this week or
cheated on their income tax this year   obvious
invasions of respondents' privacy.  Each
respondent is instructed to roll a die in his
cupped hands and observe which number came up
without showing it to the researcher.  If the
predetermined number was rolled, the respondent
is to respond "yes," irrespective of the true
answer.  By an algebraic removal of the expected
number of false "yes" answers from the data, the
researcher can determine the true proportion of
"yes" responses.  Neither the researcher nor
anyone else besides the respondent knows who
gave a true "yes" response.   

The randomized response method has been in use
since 1965, and researchers have developed many
statistical variations of it.  Although it has
been tested in many settings, the jury is still
out on its usefulness.  It tends to produce
somewhat more admissions of undesirable behavior
than traditional face-to-face interviewing, but
brings with it many disadvantages.  It is
difficult for subjects to understand and
believe, and time-consuming to explain.  The
interviewer has an important role in
establishing trust and understanding, and
respondents of limited ability have difficulty
understanding and trusting the procedure
(Landsheer, van der Heijden, and van Gils,
1999).  It injects random error necessitating
larger samples.  Without understanding the
reasons why people might refuse to give candid
answers, the routine use of a difficult method
such as this seems inappropriate.  For critical
evaluations of the randomized response method,
see Linden and Weiss (1994), Umesh and Peterson
(1991), and van der Heijden, van Gils, Bouts,
and Hox (2000).  

Methodologists have designed statistical
strategies for use with longitudinal and
multiple source data; see Boruch and Cecil
(1979).

Agreements: Data sharing, secondary analysis,
and audit of data.  Concern for the integrity of
data and for extending the analyses of important
datasets brings with it the need to do so
without risk to privacy or confidentiality.  The
simplest solution is to render the data
anonymous.  However anonymity may render the
data useless to the secondary user or auditor. 
To satisfy the needs of secondary users while
also protecting the interests of respondents,
the researcher can employ procedures that
diminish (a) outright breach of confidentiality,
(b) likelihood of deductive identification, (c)
the sensitivity of the information to which the
secondary users have access, or (d) the need for
the secondary user to actually take possession
of the data (see Boruch and Cecil, 1979). 
Researchers and IRBs need to develop contractual
agreements with funders who require audits and
secondary analysts with whom they share data
about how they will ensure confidentiality. 
They should also include information in the
informed consent so that potential subjects
understand what researchers will do with the
data subsequent to the initial project.

Legal protections of confidentiality.  Statutory
protection of research data enables researchers
to protect the confidentiality of research
records on identifiable individuals from
subpoena.  Subpoena of social research data is
rare.  However if vulnerable data could not be
protected from subpoena, there would be a
chilling effect, especially on criminological
and delinquency research.  There is growing use
of Certificates of Confidentiality.  However
researchers and IRBs are often unclear about the
protections these provide and their limitations.

Certificates of Confidentiality.  The Public
Health Service Act (PHSA) was amended (1970) to
authorize researchers to withhold information
concerning the identity of participants in
research on use and effect of drugs.  The
Secretary of the Department of Health and Human
Services grants this authority by issuing
Certificates of Confidentiality.  A 1988
amendment broadened its scope to include mental
health, biomedical, clinical, behavioral, and
social research.  Under this amendment, the
Secretary of DHHS may

authorize persons engaged in biomedical,
behavioral, clinical, or other research
(including research on mental health, including
research on the use and effect of alcohol and
other psychoactive drugs), to protect the
privacy of individuals who are the subject of
such research by withholding from all persons
not connected with the conduct of such research
the names or other identifying characteristics
of such individuals.  Persons so authorized to
protect the privacy of such individuals may not
be compelled in any federal, state, or local
civil, criminal, administrative, legislative, or
other proceedings to identify such individuals. 
(42 U.S.C. 242a(b)(1989))

Various institutes within DHHS are authorized to
issue certificates.  Since 1993 DHHS can grant
certificates for research that is not federally
funded.  DHHS regards a certificate's protection
to supercede State law; this position has been
challenged and upheld in the New York Court of
Appeals (People v. Newman, 32 N.Y.2d 379, 298
N.E.2d 651, 345 N.Y.S.2d 502, 1973) (Boikess,
2000).

A certificate does not protect identifiable data
of "secondary subjects," a point which
researchers may fail to clarify in the informed
consent.  The certificate only protects
researchers against compelled disclosure of
subjects' names or other identifiers, coupled
with their data.  It does not protect subjects
who voluntarily consent to disclose their
research records, nor preclude a researcher from
reporting the identity of subjects who disclose
intentions to harm themselves or others. 
Moreover the language of PHSA is imprecise,
which gives rise to uncertainty.  It offers
protection to "names and other identifying
characteristics," but the data of a known
subject may not necessarily be protected. 
Melton (1992, p. 81) provides an example of this
possible loophole:

[I]n one of my own studies, all of the children
in a particular county who are involved in
criminal child abuse prosecutions are invited to
participate.  Knowing that fact, a defense
attorney might seek the data of a particular
child (not the names of participants) as a
fishing expedition for information intended to
impeach the child's testimony.  A literal
interpretation of the statute would suggest that
the subpoena might be enforceable if the data
could be shown in some way to be relevant to the
proceeding.  Although it is also
possible perhaps even probable that a court
would interpret the statute more broadly in
keeping with Congressional intent, the
uncertainty prevents unequivocal offers of
confidentiality to participants and, therefore,
should be eliminated by a technical amendment.

It is also unclear whether child abuse reporting
laws are abrogated by a Certificate of
Confidentiality.  Is such reporting a "legal
proceeding" that cannot be mandated under a
certificate? 
Researchers must request the certificate before
each research undertaking.  Subpoenas typically
occur for reasons unrelated to the study itself
and therefore are not reasonably foreseeable by
either the subjects or the investigator.  Hence
the protections offered by a certificate may be
unavailable when needed.  Researchers sometimes
send data to a foreign country, although this
does not always guarantee protection.

Placing data in a foreign country and laws
governing foreign discovery. ***Footnote: am
indebted to Dr. Joe Cecil and Jason Gilbert,
Federal Judicial Center, for providing me with
their detailed summary and analysis of these
issues.*** Many survey researchers believe that
sending confidential data to a foreign country -
-such as to a colleague in Canada --protects the
data from subpoena.  However this is only a
deterrent from subpoena, not a guarantee of
protection.  Federal Rules of Civil Procedure
govern the procedures for discovery, including
foreign discovery.  Rule 26(b) states that
parties may obtain discovery of anything that is
relevant, not privileged, and admissible or
"reasonably calculated to lead to the discovery
of admissible evidence."  Rule 34 states:

(a)Scope.  Any party may serve on any other
party a request (1) to produce and permit the
party making the request, (2) to inspect and
copy, any designated documents, or (3) to
inspect and copy, test or sample any tangible
things which constitute or contain matters
within the scope of rule 26(b) and which are in
the possession, custody, or control of the party
upon whom the request is served. 

(c)Persons Not Parties.  A person not a party to
the action may be compelled to produce documents
and things or to submit to an inspection.

The courts cannot compel a party to produce data
if the party does not have "possession, custody,
or control" of the documents, but it is unclear
what constitutes "control."  If a researcher
sends data out of the country for the express
purpose of preventing subpoena, does this
qualify as loss of control in the eyes of a
court?  Jason Gilbert (2000), a legal intern at
the Federal Judicial Center, offers the
following analysis of this question: 

While the courts seem to have settled on
defining control as when a party has a legal
right to obtain something, questions remain for
the researcher seeking to give up control of
research data to a foreign colleague in an
attempt to protect it from being disclosed. 
Legal rights to possession can come from a
variety of sources, particularly when one is
considering intellectual property such as
research data.  If a researcher were to create a
set of data, when exactly would he or she no
longer have a legal right to that set of data? 
What if the researcher gave one part of the data
to a colleague?  What if the researcher only
gave up a small "key" to the data that allowed
the individuals who participated in the study to
be identified? What if the researcher gave part,
or even all, of the data to a colleague but
still continued to collaborate with that
colleague to perform analysis on the data even
though it was not in the researcher's
possession? Would that researcher still have a
legal right to get back what he or she had
surrendered? While the concept of giving away
the legal right of possession is relatively
straightforward, the mechanics of how exactly a
researcher can give away the legal right to
possess his own data (particularly if one does
not allow for a sale or some type of contract)
remains unclear.

Gilbert also reminds us of some other
implications of "loss of control" of data.  (1)
Transfer of all data out of the country would
mean loss of all electronic or hard copies in
the researcher's possession.  (2) A researcher
must never transfer data after receiving a
subpoena.  Even if it is done as a safeguard
beforehand, the researcher may still be found to
have acted not in good faith and be cited for
contempt of court.  (3) If the research is done
under a contract requiring that the researcher
maintain control of the data, relinquishing
control to a foreign colleague would constitute
a breach of that contract.  (4) The researcher's
professional code of ethics or a future journal
editor may require that the researcher maintain
control of the data.

A researcher who loses control of data by
sending it to a foreign colleague places that
colleague at risk of receiving a subpoena for
the data and of having to seek legal means of
protecting confidentiality.  However the rules
and procedures of foreign discovery are complex,
expensive, and time-consuming.  If the colleague
who controls the subpoenaed information is a
foreign national residing outside of the United
States, the party seeking the data must follow
appropriate procedures for foreign production. 
The United States has ratified various treaties
concerning obtaining of evidence from foreign
countries, and each country has its own
procedures.  Discovery in a foreign country
involves sending a formal "letter of request" by
the court where the action is pending to a court
in the foreign country.  This letter requests
the foreign court to request documents of the
person in possession of the desired information. 
There are various diplomatic and legal
approaches to delivering such a request and
accomplishing the discovery.  These may make
discovery of the information too unattractive to
pursue.

Descriptive statistics and raw data releases. 
Statisticians in governmental agencies in the
United States, Great Britain, and Sweden have
developed practices of adjusting tabular
presentations so that deductive identification
is not possible.  Deductive identification could
occur if one knew some facts about an
individual, perhaps in conjunction with their
zip code.  By searching the files for that zip
code and locating the individual whose data
matched those known facts one could deduce
additional information from the other data
associated with that individual.  For example,
if an 84-year-old Hispanic woman from the 01373
zip code area was known to have had quite a few
husbands and to have become quite wealthy, it
would confirm quite a few suspicions to learn
that there was an 84-year-old Hispanic woman at
that zip code whose annual interest income was
in seven figures and who had had 20 husbands.  

The most common way to prevent deductive
disclosure is to broaden categories so that data
from unique individuals or from groups of data
containing some unique individuals such as top
income earners or persons involved in high-
profile criminal victimization are not apparent. 
Another is error inoculation so that no
individual case could be assumed to be correct
(as in the random-response method).

When the U.S. Census Bureau's Disclosure Review
Board reviews NCVS datasets in anticipation of
their release to the InterUniversity Consortium
for Political and Social Research (ICPSR), the
Review Board's primary role is to scrutinize
data for extreme cases that might uniquely
identify the individuals involved or even
subject them to criminal investigation.  Thus,
instead of showing that a given 84-year-old
Hispanic woman had been widowed 20 times and had
an interest income of over $1,000,000, it might
show that the person had been widowed more than
four times and had an annual interest income of
over $100,000.

Internet research.  There is rapidly emerging
literature on various kinds of Internet
research, associated methods of solving problems
of privacy and confidentiality, and
uncertainties or vulnerabilities connected with
these "solutions."  Researchers' insouciant
claims that Internet data are anonymous or that
confidentiality will be protected are
reminiscent of such promises regarding non-web
research of several decades ago.  

This area of research will grow rapidly since it
enables researchers to reach far-flung subjects
quickly, inexpensively, round-the-clock, and
without a research staff.  The problems and
solutions to issues of privacy and
confidentiality will change rapidly as new
technologies render old problems and old
solutions obsolete.  Some of the rapidly
evolving issues include: 

* How to ensure that researchers do not study
children under rules that pertain to adults.
* How to ensure anonymity of responses given
that web page software logs as header lines the
IP address of the machine from which the
respondent accessed the researcher's web page.
* How to store an on-line data file so that
unauthorized persons cannot access it.

The advice offered by OHRP and generally heeded
by IRBs is that the safest practice is to use
the Internet for purposes of recruitment and
screening.  After locating a qualified
respondent, a researcher can e-mail the survey
and a respondent return it as an attachment.  
Given the uncertainties, especially with regard
to assurances of confidentiality, it is
reasonable at this stage to recommend that
assurances of confidentiality contain
appropriate disclaimers.   

Confidentiality assurances and their
consequences

The link between promises of confidentiality and
willingness to participate in surveys is
tenuous.  Researchers' promises of
confidentiality are not always effective in
producing trust in research participants.  Such
promises cannot always be kept due to faulty
data management practices and other possible
compulsory disclosures.  Moreover, the
relationship between faith in confidentiality
promises and participation in survey research is
not what most suppose it to be.

Singer, Mathiowetz, and Couper (1993)
investigated the relationship between concerns
about confidentiality and mail returns to the
1990 census.  Such concerns have only a very
slight effect on survey participation, and this
relationship holds even when demographic
variables known to be related to concerns and
survey participation are controlled.  Similarly
assurances of confidentiality have unexpected
effects.  Singer, VonThurn, and Miller (1995)
conducted meta-analysis of 30 research reports
on the relationship between various forms of
confidentiality assurances (anonymity, use of
the randomized response method, and verbal
assurances).  They found that the effect of
confidentiality assurances on willingness to
respond is small, positive, statistically
significant, and robust in the presence of
various control variables, but only when
sensitive questions are asked.  The effect is
small and negative when the questions asked are
not sensitive ones.  Elaborate assurances of
confidentiality defeat their purpose when the
contents of the survey are not sensitive. 
Apparently such assurances of confidentiality
heighten respondents' perceptions of the
sensitivity or threat of the survey or arouse
their suspicions (Singer, Hippler, and Schwarz
(1992)).

Emerging issues of privacy and confidentiality

Electronic data collection and storage practices
are changing rapidly.  Interviewers and their
subjects need not meet face-to-face and may even
reside in different parts of the world. 
Emerging issues of confidentiality are more
varied and dangerous than current policy makers
can easily anticipate.  Soon issues of
confidentiality will be transformed in ways we
cannot imagine today.  There are already digital
communication networks on a global scale, and
hackers with a laptop computer and Internet
technology could download any electronic data
stored on any server anywhere in the world. 
There are also emerging technologies for
protecting communication and personal identity,
and there is a whole new cohort of technology-
sophisticated privacy activists.  Governments
are developing and testing new laws that protect
data, and globalization of culture and policy
processes is occurring.  The American
Association for the Advancement of Science, the
National Science Foundation, and various
Internet research groups are now actively
exploring these issues.  Scientific societies
concerned with the protection of social and
behavioral research data   the American
Statistical Association, American Psychological
Association, and American Sociological
Association   will continue discussing these
issues at their annual meetings for years to
come.

4.  Other procedures for minimizing risks and
promoting benefits

One cannot begin to minimize risks or promote
benefits unless the risks and benefits are first
identified.  Although conducting a risk and
benefit assessment is a fundamental concept in
the planning of ethically responsible research,
some of the possible risks and benefits are not
immediately obvious.  Possible risks and
benefits are virtually unlimited.  

Identifying and minimizing risks

In section 3, six kinds of risk were identified:
inconvenience, physical risk, psychological or
emotional risk, social risk, economic risk, and
legal risk.  They are but one dimension of the
risk matrix that is presented here (figure 1). 
A second dimension is the location within the
research process where the risk might occur.  A
third dimension is the specific vulnerability of
the individual subject; for example, public
figures are vulnerable, but in a different way
than those engaged in illegal activities or
those who are institutionalized. 

The six kinds of risk could be elaborated or
conceptualized in various ways.  In section 3,
we viewed them simply as subsets of risk related
to invasion of privacy or breach of
confidentiality.  They are also issues of
personal safety or well being.  Some of these
risks can come about through misunderstanding,
outright deception or concealment in the way the
survey is administered, and inequitable
treatment by the researchers.  Researchers can
address these risks in the communication process
of informed consent (with informed consent being
regarded as an ongoing communication process,
not simply a consent form).  Issues of ownership
of the data and the knowledge are also relevant. 
If shared, are the data shared responsibly?  Is
the new knowledge used in a way that benefits
the respondents or harms them?  What is the
relationship of the project to the gatekeepers
who facilitated the recruitment process, and to
the opinion leaders who will create attitudes
toward the project and the respondents? 

Figure 1.  Risk matrix, by part of the research process at which risk occurs
and by type of respondent
                                                                               
                                                Kind of risk
Part of research process    Inconve-          Psycho-       
and type of respondent      nience   Physical logical Social Economic Legal
The theory or idea
  Public figure
  Lack autonomy
  Lack resources
  Stigmatized
  Criminal
  Secondary subject
  Disabled

The research process itself
  Public figure
  Lack autonomy
  Lack resources
  Stigmatized
  Criminal
  Secondary subject
  Disabled

The setting in which the  
research occurs
  Public figure
  Lack autonomy
  Lack resources
  Stigmatized
  Criminal
  Secondary subject
  Disabled

The use or dissemination 
of the findings
  Public figure
  Lack autonomy
  Lack resources
  Stigmatized
  Criminal
  Secondary subject
  Disabled

Researchers may conceptualize the scientific or
research activity as having four parts, each of
which has risks (as well as benefits):

The idea, theory, or hypotheses that drives the
design of the survey, sampling of populations of
interest, and analysis and interpretation of the
results.  A new idea can affect individuals and
change cultural values in fundamental ways.  The
idea may not be correct but it might be falsely
confirmed by faulty analysis and interpretation. 
The idea may be correct, but be disseminated in
a way that does harm.  The researcher has four
ways to reduce the risk of false confirmation or
dissemination of damaging ideas: recognize that
the null hypothesis could be true; design the
research so that each possible theoretical
orientation is tested fairly; remember the
limitations of the models and measures employed
and warn that application and generalization to
other populations must be done with caution; and
share the documented data with other scientists
who want to verify the findings or test
alternative hypotheses.
The research itself has several stages, each of
which could involve risks: the recruitment, the
induction, the consent and survey, the
debriefing, data analysis, and data sharing.  
The institutional, community, or group setting
of the research.  Research is rarely only a
matter between researcher and respondent; there
are usually third parties involved.  Every
setting has its members, structure, culture, and
interests.  Most settings have gatekeepers who
impose rules on the research transaction.  All
of these elements may impose pressures and risks
on both the respondents and the researcher. 
Because individuals vary in their degree of
personal autonomy and institutions in their
degree of control and coercive power, the kinds
of harm that may result from research in those
settings also range greatly.
Uses of the research findings.  In their
enthusiasm to use what is learned, investigators
can overlook that many findings are based on
measures of dubious reliability or account for
so little of the variance that they should not
be considered practically useful.  Researchers
can misuse findings that are useful for one
purpose but harmful for other purposes.  

Respondent vulnerabilities are covered in
section 7.  The following are some examples of
the range of vulnerabilities researchers should
consider when engaging in risk assessment. 
Respondents who are public figures are
especially exposed to attention and criticism;
for them privacy is a sought-after luxury. 
Those lacking in autonomy or resources to
protect their privacy lack the usual means of
preventing intrusions from others; these may
include children and the mentally and
emotionally disabled.  Scapegoats and targets of
prejudice, such as homosexuals, persons with HIV
infection, and some racial minorities, are
especially sensitive to researchers'
interpretation of their lives and their data. 
Institutionalized persons lack the normal degree
of autonomy and may also be stigmatized. 
Persons engaged in illegal activities have many
fears concerning disclosure of information about
themselves.  Persons damaged by the respondents'
revelations, the "secondary subjects," are
harmed often without any knowledge of the
harmful disclosure.

The risk matrix serves to sensitize researchers
and IRBs to the kinds of risks they may
anticipate (figure 1).  Once risks are
identified the quest for safeguards or
protections can begin.  Researchers can minimize
some of the risks identified by this matrix by
use of approaches that respect privacy and
ensure confidentiality.  Researchers can
minimize other risks through mindfulness of the
possible harms that may result from the research
findings. 

Identifying and maximizing possible benefits

Survey research is typically considered to
benefit respondents by giving them an
opportunity to discuss a topic relevant to their
life, and by providing valuable information to
organizations and to society in general. 
However there are other benefits to the
respondents and their community that are
typically overlooked (figure 2).

Figure 2.  Benefit matrix for survey respondents and their community
Benefit        Respondents                         Commmunity
Relationships    Gain rapport with            Create ties to the project
                 respectful researcher

Knowledge         Conduct informative        Understand victimization
                  debriefing, having one's   issues relevant to 
                  questions answered         community improvement

Material           Provide informational     Provide brochures, books,
resources          handouts                  videotapes, and other             
                                             communication media

Training           Develop relationship      Teach crime deterrence
                   between some of the          
                   respondents and the 
                   community-based project

Earn esteem                                   Earn praise for program

Empowerment                                   Earn prestige from an            
                                              effective program

Cultural anthropologists have pioneered in
thinking about ways to benefit the respondent's
community partly for practical reasons.  Without
making the research a win-win situation for
themselves, respondents, and the host community,
researchers would quickly lose support from the
hosts.  Anthropologists such as Pertti Pelto
(described in Sieber, 1991) have hired selected
community members as research assistants, then
shared their data with the host community so
that it can be used for public policy purposes. 
Thus they have left behind a cadre of new
researchers who can remain in contact with the
investigator or can continue to build on and
analyze the dataset on behalf of their
community. 

With this model in mind, researchers should
consider the potential value in employing and
training members of some target communities to
assist with some aspect of the NCVS interviews
or dissemination of information.  Conceivably,
once researchers interview a cohort seven times
and the project is ready to move on, researchers
could distribute information on crime prevention
to the particular respondents and to the
community, and to assist the community (via the
police department or other agencies) in helping
its citizens make optimal use of that
information.

Researchers should use both the risk and benefit
matrices early in the research planning process
to generate ideas.  They can then translate the
resultant assessment of possible risks and
benefits into actual operations. 
5.  Procedures for responding to requests for
help or assistance

Effective interviewers are skilled at
establishing trust and rapport.  These qualities
tend to instill in respondents a sense that the
researcher is a responsive and capable
professional.  When the interview topic is a
sensitive one that evokes concerns in a troubled
respondent, it is not unusual for that person to
reach out to the interviewer for help.  The
interviewer is often only that -- a paid
interviewer, not a helping professional. 
However because of the sensitivity of such
situations -- this may be the first time the
individual has dared to reach out for help -- it
is important that the interviewer not rebuff or
ignore the request, and respond in an
appropriate and helpful manner without getting
personally involved.

Standard procedures 

When researchers work with vulnerable
populations or in situations where they may be
asked to provide help or assistance, it is
standard for IRBs to require that the
researchers prepare a set of referrals.  The
required response varies with the type of
research.  In some cases researchers give
respondents an information sheet (that may
include referrals) to thank them for
participating and as part of the debriefing.  In
other cases, researchers develop various
referral sheets, depending on the kind of help
that is requested.  In research with vulnerable
participants who are at high risk, the
researchers establish a relationship with
specific professionals and arrange for the
referred respondents to have several sessions
with the professional.  In the case of high-risk
respondents, IRBs may require appropriate
training to help interviewers recognize and
interpret responses indicative of need for help.

Research institutions that engage in research
with high-risk populations usually require their
interviewers to handle requests for help as
follows: If the request comes at the beginning
or during the interview, the interviewer is to
ask if the interview can continue and promise to
give help or assistance when the interview is
concluded.  At the end of the interview, the
interviewer gives the respondent the appropriate
referral information.  If the respondent simply
cannot wait for the end of the interview, the
interviewer provides assistance, thanks the
respondent for the information provided so far,
and discards the interview responses. 
Researchers may write the costs of the
professional's services into grant support for
the project or into the research institute's
budget.

Background considerations

It is important to understand the degree of
response that might be appropriate in a given
project.  When should interviewers actively
intervene in the lives of persons who need help
and when should they simply provide referral
information?  It is useful to consider a range
of kinds of high-risk respondents. 

Survey researchers who study social
psychological aspects of HIV infection and
injection drug use have faced the ultimate
challenges of responding appropriately to
requests for help.  Hence investigators now
apply, when appropriate, a range of practices
that were developed in survey research on HIV
infection and drug treatment to other high-risk
settings.  
Interviewers in the HIV and drug treatment
fields receive HIV post-test counseling to
acquaint them with the feelings, concerns, and
behaviors of persons who have recently learned
that they have HIV, who fear that they may have
HIV, or who have significant others who have
HIV.  Contacts for counseling and treatment are
set up prior to the interviews so that the
referral process can work seamlessly.  This
includes a police contact. 

In survey research in the HIV and drug treatment
fields there is now a routine that is followed
quite strictly.  If an interviewer encounters
someone who is distressed, or someone the
interviewer is worried about, the interviewer
has a telephone number and perhaps a cell phone
he can use to call for help right away or give
to the respondent to use right away.   

When survey research is conducted on the
streets, projects require that a team member
accompany the interviewer to the interview, even
if there is only one interview scheduled.  The
team approach is used for the safety of both the
respondent and the interviewer.  If the
interview is held in the project's field office,
another team member is always present when a
respondent is in the office.  For very immediate
emergencies the interviewer helps the recruiter
or receptionist until assistance arrives. 
Again, everyone has prearranged telephone
numbers.

Ultimately, such field survey projects must rely
upon the skill, humanity, and insight of their
staff to sense incipient problems and to deal
with them.  This is one reason why researchers
seek staff members who have related prior
experience, including knowledge of this culture
in their own lives and prior work with emergency
situations.  As one project director commented:
"We seek staff among people who live on the
edge.  There is no substitute for experience."

Some of the same precautions are often used with
survey research on prostitutes, drug dealers,
and other members of street cultures.  However
most survey research is not conducted "on the
edge."  Interviewer training and preparedness
remain important but the emergencies they may
face are often more subtle, less immediate, and
less frequent.

A "cry for help" may be implicit or explicit. 
Examples of implicit responses include
statements indicating desperation, suicidal
ideation, or a high score on a depression scale. 
Explicit responses might be a statement of
extreme duress such as "My spouse has threatened
to kill me," accompanied by a request for help
or advice.  It could be about someone else in
danger, for example "My spouse threatened to
kill his boss.  What should I do?  Can you help
me?"  (There are also requests for help that
would trigger mandated reporting to authorities;
see section 6.)  It may come from a respondent
to an anonymous survey, from an identified
survey respondent, or face-to-face in an
interview.  Interviewers have effective and
responsible ways to answer such cries for help
but must take appropriate precautions.

Implicit request

The ethical requirement of beneficence (National
Commission for the Protection of Human Subjects
of Biomedical and Behavioral Research, 1979) and
the code of ethics of the American Psychological
Association (1992) would seem to endorse the
responsibility of researchers to intervene when
serious distress is discovered or caused by the
research procedure, but may conflict with the
principles of respect for autonomy and privacy. 
If the researcher is to take any steps in
response to apparent need, should the respondent
be warned in the consent statement that such
action would be taken?  If this is done, what
effect would such a warning have on willingness
to participate or to be candid?  

This set of questions was answered quite
effectively in an experiment by Stanton, Burker,
and Kershaw (1991) on the effects of researcher
follow-up of distressed subjects.  Since
researchers studying depression often encounter
respondents in serious preexisting distress,
these investigators sought to study the ethical
responsibilities of such researchers.  A
literature search revealed that researchers'
responses to such subjects range from doing
nothing to recontacting both the distressed
subject and a significant other.  Stanton et al.
studied whether respondents adjust their reports
of distress on three standardized measures of
depression as a function of their expectation of
experimenter follow up.  The content of their
informed consent was manipulated to reflect four
levels of researcher intervention: (1) no
intervention, (2) provision of a list of
treatment resources to all subjects, (3) follow-
up contact by the researcher with distressed
subjects, and (4) follow-up contact by the
researcher with the distressed subject and a
significant other.  Their results were quite
dramatic and consistent across all three
measures of depression.  Respondents reported
the highest average level of distress in
condition 2, in which all subjects were to
receive a list of treatment resources.  The next
highest average level of distress was reported
in condition 1 (no intervention).  Mean distress
measures were markedly lower when subjects
expected the researcher to recontact distressed
subjects (condition 3), and much lower when they
expected the researcher to recontact them and
their significant other.  Some of these effects
were slightly stronger for men than for women,
but the gender differences were minor.

The implications for survey researchers are
quite clear: 
Respondents do not want to receive personal help
unless they ask for it.  However they appreciate
receiving information that would enable them to
better understand their situation or to seek
help for themselves.   
The expectation that the researcher might
intervene personally is so distasteful to most
that respondents will falsify their answers to
avoid this.  
The expectation that the researcher might
contact family members or significant others is
even more objectionable.   

Obviously, the simple provision of information
to all subjects both provides the desired kind
of assistance and respects privacy and autonomy. 
Moreover it is easy to administer and the
interviewer will not need any specialized
training.

The anonymous survey that may reveal serious
distress is a related issue.  Researchers may
administer anonymously surveys of topics such as
mental health, stress and coping, high-risk
behaviors, health concerns, and experience of
abuse or violence due to the unwillingness of
many respondents to reveal personal or
embarrassing details about their lives.  How
does one intervene to help anonymous persons in
serious difficulty?  The Stanton et al. study
emphasizes that personal or clinical
intervention by the researcher is unwelcome if
not requested.  Researchers have used the
following approaches.  The interviewer may
provide: 
a list of treatment resources, self-help guides,
or useful factual information to all
respondents, 
ample opportunity for debriefing in which the
respondent can express any concerns or interests
and receive a referral slip (with no name or
other identifier) for a nearby clinic if the
respondent so desires, 
an admission ticket to a nearby workshop or
panel on the topic, or 
web addresses to constructive web discussion
groups on the topic.   

If respondents come from identifiable groups
such as classrooms or workplaces the researcher
may arrange for the organization to provide an
appropriate educational program to the whole
group.  

Explicit request

The interviewer can respond less awkwardly to an
explicit request for help because there is less
chance of offending the individual by proffering
assistance.  The interviewer can offer
assistance in proportion to the nature of the
request.  In extreme situations, the interviewer
may step in, provide a therapeutic debriefing,
and arrange for immediate referral.  However
interviewers must avoid getting drawn into the
dual role of therapist/helper and interviewer. 
They must be prepared to explain to the
respondent that they are not qualified to help
but can provide the services of a competent
caring person who can.

A specific recommendation: An experiment within
the survey

The U.S. Census Bureau faces an unusual dilemma
regarding response to requests for assistance
because its interviewers return to the same
group seven times to study its members'
experience of crime victimization.  By offering
referral information on any of the first six
interviews, Census may alter the phenomenon that
it seeks to study.  Census interviewers
currently respond to requests for help only
after the last interview unless the individual
is in truly dire circumstances.  In those
extreme cases the interviewer responds earlier
in the sequence of interviews, but then drops
that household from the survey, replacing it
with a demographically similar household. 

However the current Census practice raises
several questions.  How much difference does a
referral actually make in the life of a
respondent who asks for help?  Is it helpful? 
Harmful?  Does the person who asked for help
actually use the referral?  What if researchers
provided a list of referrals to all respondents
for all of the sorts of crime victimization
surveyed?  Does the making of a referral,
requested or otherwise, impact the nature of the
data subsequently gathered from that household? 
With what frequency are requests made for
assistance?

There are several implicit concerns in this
discussion: (a) concerns for statistical
accuracy of estimates of amount of crime
victimization, (b) concerns to learn whether
providing a referral actually changes the course
of events in a victim's life (other than
impacting the kind of data Census seeks to
gather), (c) concern to help someone who reaches
out, (d) concern to provide possibly useful
referral information to all respondents in
return for their participation, (e) concern
about the frequency and nature of requests for
assistance, and (f) concern that Census avoids
criticism for failure to help.  

If interviewers do not already record the
incidence and nature of requests for assistance,
they should do so.  What is the relative
frequency of the various kinds of requests? 
What are the demographic characteristics of
respondents who make each kind of request?  How
do requests change in relation to changes in
crime rates?  These baseline data would provide
a useful backdrop for the following experiments:

Experiment 1.  Effects of referral sheets given
to all respondents.  Researchers would draw a
stratified random sample of respondents and
divide them into experimental group members and
matched controls.  After the first interview,
researchers would give all experimental group
members a referral sheet recommending local
sources of assistance for each of the kinds of
crime victimization surveyed.  Control group
members would receive no referral sheet.  At the
end of the 3 years and seven interviews,
interviewers would reinterview members of both
groups to learn whether there were kinds of
relevant assistance they had desired, whether
they sought assistance, how they went about it,
and with what result.  Interviewers would note
whether the experimental (referral) group
members mentioned the referral sheet, used it,
were more likely to seek referral of any kind,
and whether their data reflected a lowered rate
of victimization than matched controls.

Experiment 2.  Effects of appropriate referrals
provided in response to requests for help.  When
interviewers are asked for help they would use a
randomizing procedure to decide whether to offer
a referral   on odd dates give referral, on
even dates do not.  Interviewers would use this
random assignment procedure in all but the most
extreme cases where failure to make a referral
would place the respondent in serious jeopardy. 
Interviewers would note who asked for help and
other pertinent details, including whether the
respondent was assigned to the experimental or
control group, the kind of help requested, when
in the sequence of interviews the request was
made, and other relevant details.  At the end of
the seven interviews, interviewers would
reinterview all members of the experimental and
control groups to learn whether they had sought
and obtained assistance, how they went about it,
and with what results.  Researchers would
compare the experimental group's subsequent rate
of reported victimization with that of the
control group.

A conservative version of experiment 2 would
employ the replacement sampling procedure Census
currently uses.  Census would provide referrals,
drop those household from the survey, and
replace it with a matched household.  However
Census would continue to interview the dropped
households for the entire 3-year sequence so
that Census could validly compare their data
with that of the remaining households.  The
postexperiment reinterview would be the same as
that described above.

By including small-scale experiments such as
these into its survey procedure, Census can
learn what happens when a referral is made,
whether it is helpful, if it can be made more
helpful, and whether referrals significantly
impact subsequently reported victimization.  If
referral information is helpful to persons in
avoiding or dealing with victimization, but
impacts statistical results, researchers might
provide referral information only at the end of
the 3-year sequence or in response to those
kinds of requests for which referrals were found
to be helpful.
6.  Procedures for responding to mandates to
report  

There are various statutes that require
researchers to report revelations of certain
kinds of situations to appropriate authorities. 
These vary by State in terms of what must be
reported and who must report.  Because of the
State-by-State variability of mandated
reporting, national surveys that cross State
boundaries must either modify their procedures
for each State or adopt the most stringent
reporting standard for the entire survey.  The
kinds of revelations that call for reporting to
appropriate authorities may include child or
elder abuse or neglect and intention to harm
others or oneself. 

It is assumed that the NCVS is exempt from
mandates to report because the survey is
conducted under Title 13, the U.S. Census Bureau
confidentiality statute.  Probably, NCVS
interviewers would only report explicit verbal
mention of abuse, which would occur rarely.  In
response to such mention, the interviewer could
encourage the individual to self-report.  The
interviewers might have with them the 800 number
of a nearby appropriate agency in that State. 
(See Appendix A for State phone numbers to
obtain local agency information and phone
numbers.)  This would satisfy both the moral
duty to respond and the legal duty to abide by
conditions of Title 13.

Researchers should anticipate (rather than
respond to) possible revelations.  In the
interest of confidentiality, researchers should
include a warning of the limits of
confidentiality in the informed consent for
surveys or interviews that might conceivably
reveal evidence of reportable situations such as
child abuse.  While this might distort the
random sampling scheme and jeopardize
generalizability by eliminating those who
decline to participate, it provides a higher
level of confidence in those who choose to
participate and eliminates the legal and ethical
horrors of having to consider breaching
confidentiality to comply with the law.  If this
procedure raises significant generalizability
concerns, the researcher may consider conducting
a parallel study of parents who have been
convicted of child abuse.

Child maltreatment

The Federal Child Abuse Prevention and Treatment
Act of 1974 required that each State establish
child protective services and develop its own
mandated reporting laws.  By 1978, State
reporting laws were in place; Levine and Levine
(1983) include the history of these laws.  State
laws mandate the kinds of situations that must
be reported and the kinds of persons who must
report   helping professionals only or anyone. 
There is considerable State-to-State variability
of laws and unpredictability of court decisions. 
Because most large sample surveys cross State
boundaries, IRBs and survey researchers must
know the relevant State laws and trends in court
decisions, and should have policies and
procedures in place for interpreting those laws
correctly.  Specifically, researchers should
consider State law in the formulation of the
informed consent statement about the limits of
confidentiality, in the education the IRB
provides concerning kinds of evidence that
require reporting, and in the plans and
consultation arrangements that the researcher
and IRB develop for handling such cases.  See
Kalichman (1999, pp. 14-23) for the definitions
of abuse and requirements to report that are
excerpted from the reporting statutes of each
State.

All States require reporting by certain helping
professionals such as physicians, psychiatrists,
clinical psychologists, counselors, teachers,
nurses, and social workers.  Some also require
reporting by pharmacists and religious healers. 
In their efforts to locate makers of child
pornographic films, Colorado and Illinois
require reporting by commercial film developers. 


Anyone who has reason to suspect child
maltreatment must report in the following nine
States: Florida, Indiana, Kentucky, Minnesota,
Nebraska, New Hampshire, New Jersey, New Mexico,
and North Carolina.  Obviously, interviewers
working in these States are operating under a
different mandate than those working in the
remaining States.  However the likelihood of
their discovering reportable cases is largely
limited to situations in which they are
explicitly told about the maltreatment, an event
which would be exceedingly rare.

In evaluating a given protocol the IRB must
consider whether there is a chance that the
researcher will find reasonable evidence of a
reportable situation.  Reporting laws vary among
States with respect to how one learns about the
suspected abuse.  In some States, a report is
required even if the reporting individual learns
of it through a third party.  Most statutes
require the reporting individual to testify in
court proceedings, include a criminal penalty
for failure to report, and permit civil action
against a professional whose failure to report
resulted in injury to the child.  However all
statutes provide immunity from a suit when a
report made in good faith turns out to be
unfounded (Levine, 1982).

If the IRB believes that a reportable revelation
might occur, it will require that the informed
consent statement include a warning about the
limits of confidentiality.  A statement adapted
from one developed by David Ruja (Gil, 1982) is:

What is discussed during our session will be
kept confidential with two exceptions: I am
compelled by law to inform an appropriate other
person if I hear and believe that you are in
danger of hurting yourself or someone else, or
if there is reasonable suspicion that a child,
elder or dependent adult has been abused.

The same sort of warning must appear in the
parental permission for research on a child. 
The problems of coping with mandatory reporting
have resulted in creative approaches to
recruitment and consent procedures.  One
researcher who wished to study the responses of
non-abused children to anatomically correct
dolls resorted to the following screening
procedure.  She told parents that children could
not participate who: (a) were under treatment by
a mental health worker, (b) did not speak
English, (c) had been sexually abused, or (d)
had an infectious disease.  Thus she could rule
out children who had been abused without knowing
who they were.

The major problem faced by IRBs and
investigators is not the State-by-State
variability of laws but the lack of clarity
about their interpretation.  It is not clear
whether "reason to believe" refers to a clinical
hunch or to firm evidence, nor do these laws
define what constitutes abuse.  This leaves
researchers to consider cultural differences and
to weigh these against the possibility that the
legal bureaucracy may be more harmful to the
victim than are their seemingly abusive
relatives.  The difficulties of defining abuse
are many.  Estimates of the amount of child
abuse vary from 1% to 30% of all children
depending on one's definition (Weis, 1989).  How
is the act perceived by the child   to teach an
important lesson (Corbin, 1987), to cure a
disease (Gray and Cosgrove, 1985), or out of
malice?  Thus, added to the costs of breaching
confidentiality is the possibility that
reporting will harm both the "victim" and the
"perpetrators."  

What is ethically responsible research behavior
with respect to reporting?  Should the
researcher stop and warn the subject who starts
to mention abuse that it is reportable
information?  Should the researcher actively
seek and report evidence of abuse and neglect? 
BJS and U.S. Census Bureau researchers do not
have to solve this dilemma.   Census
interviewers can respond to mention of abuse by
encouraging the respondent to self-report and by
providing an appropriate phone number.

For investigators who do not have statutory
protection such as Title 13, this is an area in
which IRBs and researchers need consultation. 
They should establish relationships with social
workers, pediatric nurses and physicians, or
clinical psychologists who are competent to
judge evidence that may trigger reporting.  Some
IRBs may not recognize when there is risk of
uncovering evidence of reportable activity.  If
risk is recognized, the ambiguity of State laws
concerning reporting can lead to extreme IRB
decisions such as rejecting the entire protocol
or suggesting poor solutions.  If the IRB does
not have a knowledgeable clinician among its
members, it should call upon such a person for
advice as needed.  Clinically trained
practitioners know how to interpret verbal or
behavioral communications and are able to
determine the appropriate action.  They probably
are acquainted with the Child Protective
Services agency in their area and with the
strengths and weaknesses of its professional
staff.  They will know how to report suspected
abuse in a way that maximizes the likelihood of
a beneficial outcome.   

IRBs that frequently review protocols for
research that might happen upon evidence of
abuse should arrange permanent institutional
resources to advise and support researchers in
this area.  Without a trained clinician to
advise on what constitutes "reasonable
evidence," a risk-averse researcher or IRB may
overreport to protect themselves from possible
prosecution.  Their duty is to make a considered
decision in consultation with others qualified
to advise, not to jump to conclusions and report
without consultation or sound advice.  IRBs
should develop guidelines for reporting that are
tailored to the specific State and local
situation and to the resources available to them
for consultation.

It is important that investigators at risk of
discovering reportable abuse understand the
significance of warning respondents of their
duty to report.  Federal regulations regarding
confidentiality require that researchers warn
subjects of mandatory reporting requirements,
and researchers must be ready to respond
appropriately to signs of abuse.  Realistically,
however, this requirement protects researchers
and not victims.  Moreover it does not apply to
the U.S. Census Bureau.

The most authoritative, comprehensive and
helpful source of information on mandated
reporting of child abuse is Kalichman (1999),
who provides comprehensive reporting
requirements.

Elder abuse

Elder abuse is a significant problem, and
elderly respondents may self-report to NCVS
interviewers.  In 1996 a national incidence
study found that over 500,000 elders experienced
abuse that year, 75% of which was unreported. 
In 90% of cases, the perpetrator was a family
member, two-thirds of whom were adult children
or spouses.  The generally accepted definitions
of elder abuse include:

Physical abuse which is the willful infliction
of physical pain or injury, including slapping,
bruising, sexually molesting, or restraining
Sexual abuse which is non-consensual sexual
contact of any kind.
Financial exploitation which is using the
resources of an older person without their
consent for someone else's benefit.
Neglect which is failure of caretaker to provide
goods or services necessary to avoid physical
harm, mental anguish, or mental illness.

The Administration on Aging (AoA), Department of
Health and Human Services, is the only federal
agency dedicated to policy development,
planning, and delivery of supportive services to
elders.  There are also State elder abuse
prevention programs.  There is now federal
legislation requiring that States develop
legislation similar to that for child
maltreatment.  However this legislation is
relatively new and the mandated programs are not
fully developed.

AoA funds the National Center on Elder Abuse,
which is located at 1225 I Street, N.W., Suite
725, Washington, D.C.; phone 202-898-2683; e-
mail NCEA@nasua.org.  Their web site,
http://www.elderabusecenter.org, includes a
State-by-State listing of toll-free phone
numbers for reporting elder abuse. 
Additionally, this web site contains
comprehensive information on elder abuse.

After reporting, the agency screens calls for
potential seriousness, keeping the information
confidential.  If the agency decides there is
violation of State elder abuse laws, the agency
assigns a case worker (in emergencies, usually
within 24 hours).  If the victim needs crisis
intervention, services are available.  If no
abuse is substantiated, most agencies will work
as necessary with other community agencies to
obtain any needed social or health services for
the elder.  The elder has the right to refuse
services offered.
As with child maltreatment, NCVS interviewers
could respond to evidence of elder abuse
appropriately by urging self-reporting and
providing the appropriate State hotline numbers. 

Intent to harm oneself or others

The intent to harm oneself or others are issues
that primarily impact mental health clinicians
who probe into the motives and intentions of
their clients.  However it is conceivable that
feelings of despair or anger evoked in an
interview on crime victimization could give rise
to statements about harming oneself or others.

Intent to harm oneself is discussed in section
5.  An appropriate response is to urge the
individual to seek help and to give them an
appropriate referral (phone number).

Intent to harm another is an issue that rarely
arises in either psychotherapy or
social/behavioral research.  However there are a
few State laws governing the duty of
psychotherapists to respond to such a threat by
warning the intended victim.  Consequently
psychotherapists have had to include in their
informed consent a warning of their duty to
report such events.  The disposition of courts
to find that there is a duty to warn an intended
victim has spread throughout the country. 
Despite the rarity of statements about intent to
harm another, the cases in which actual harm has
arisen resulted in some surprising court
decisions and tremendous amounts of publicity. 
Under the protection of Title 13, the U.S.
Census Bureau need not warn of a duty to report
and may not report.  However the U.S. Census
Bureau may want to consider the kinds of
referral information that it could provide to
individuals who are planning to take justice
into their own hands.  This might include a
range of alternatives that include counseling,
mediation, and referral to appropriate law
enforcement agencies.

The U.S. Census Bureau should stay current about
the development and spread of legal mandates to
warn intended victims.  The case of Tarasoff v.
University of California Regents is instructive. 
A University of California Berkeley graduate
student, Prosenjit Poddar, revealed to a campus
psychologist his pathological intent to kill
Tatiana Tarasoff, who had spurned his
affections.  The psychiatrist notified the
police, who found the man rational.  Poddar
understandably did not return to therapy, and
stabbed Tarasoff to death.  Through a series of
appeals, the Tarasoff family persuaded the
California Supreme Court (1976) that mental
health professionals have a duty to intervene in
such cases.  

Depending on the case, intervention can include
warning the intended victim, notifying
authorities, or securing an involuntary
commitment.  Although some therapists and
researchers consider this an unacceptable
infringement on their duty to hold professional
information confidential, the Tarasoff law
mandates that professionals must intervene
effectively when the client in therapy,
including those in research on the therapeutic
process, reveals an intent to harm another.  

Other States have copied the Tarasoff law in
various forms.  Even in States that do not have
"Tarasoff" law, it is reasonable to consider
whether victims or their families might seek to
apply the Tarasoff principle if a person
indicates intent to harm and then commits a
violent act.  According to existing law, the
Tarasoff principle applies only to therapists. 
However many IRBs require that researchers
report to appropriate authorities any disclosure
of intent to seriously harm another,
irrespective of whether the researcher is a
therapist.

Some researchers seek to protect themselves from
lawsuits for breach of confidentiality by
including in the informed consent a statement
such as "Your data will be kept confidential
within the limits of the law."  This is
unadvisable.  Recent court cases have upheld
respondents' rights to an informed consent that
they can understand.  IRBs are now increasingly
careful about how they state their obligation to
report.

On their IRB's web site, the University of
Chicago provides the following example of a
possible statement for inclusion in a consent
document regarding a survey of persons with
depressive symptoms:

Some of the questions in the written forms and
the interview ask about how you are feeling now. 
If your answers make us think that you might
harm yourself or others, we are required to
notify the proper authorities of this risk.

The Census Bureau and BJS should prepare policy
regarding a response to evidence of child or
elder maltreatment, or threats of harm to
oneself or others with appropriate referrals,
and be sensitive to the requirements of
investigators who do not operate under Title 13.

7.  Vulnerable populations: Risks and special
protections  

Vulnerable populations normally include
children, teenagers, pregnant women, cognitively
impaired persons, and institutionalized or
imprisoned persons.  For purposes of the NCVS
and most other social surveys, the vulnerable
populations requiring special precautions to
minimize risks probably also include the
elderly, minorities, economically or
educationally disadvantaged persons, and other
"institutionalized" groups such as students
recruited as research subjects by their teachers
and employees recruited as research subjects by
their employer/supervisor.

IRB concerns

In the case of prisoners and children, Subparts
C and D of 45 CFR 46 permit IRBs to approve
research that involves no more than minimal
risk, or that may involve somewhat more risk but
will benefit the participants.  Subpart C is
pertinent to survey research in that it provides
extensive safeguards to confidentiality and
against coercion so that prisoners are afforded
autonomy in their role as research subject. 
Subpart D is pertinent to survey research in
that it requires both parental approval and the
child's assent, except as noted in section 9.

In the case of each of these populations, IRBs
are sensitive to whether it is appropriate to
include the given population, consent is
informed and autonomous, participation is free
of coercion, and the language and presentation
are appropriate to the needs of the particular
population.  Privacy and confidentiality have
special significance for each population and
researchers should safeguard them appropriately. 
Specific fears, not necessarily warranted, are
germane to each group and investigators should
learn and dispel them.  Each group has its own
culture and language characteristics, which
researchers need to understand and respect.

Children and teenagers

The privacy needs of children and teenagers
change markedly as they grow from early
childhood through the teen years.  Thompson
(1982) presents an excellent review of these
changes, showing that popular ideas about
vulnerability decreasing linearly with age are
inaccurate.  Older children and teenagers are
more easily embarrassed, more concerned about
personal and informational privacy, and more
likely to feel upset if they reveal more than
they intended.  As they approach their teens
children become sensitive and skeptical about
situations in which an interviewer might conceal
or withhold information and upset at the
prospect of being deceived.  In their efforts to
forge their own sense of identity, youngsters
approaching and in their teen years would not
want to be interviewed on a sensitive topic in
front of their parents.  They might even offer
to disclose information only on the condition
that the interviewer not reveal it to their
parents.  Because NCVS interviewers are exempt
from mandatory reporting under Title 13, this is
less of a dilemma for them than for other
researchers.  If appropriate, the NCVS
interviewer might provide referral information
to a troubled teen or urge that they confide in
their parents, but need not take the matter
farther.

Older children and teenagers are developing
means of controlling their privacy.  In middle
childhood, children begin to want to have
private places of their own, and are likely to
post a sign on the door to their room saying
"KEEP OUT."  By the teen years, youngsters are
intensely private, easily embarrassed, and
interested in issues of informational privacy. 
Some will refuse to provide information if they
feel intruded upon.  Having a private place to
be alone, or to communicate with friends in
privacy becomes extremely important.  For the
teenager, promises of confidentiality are
extremely important.

In contrast, young children, up to about age 7,
are not easily embarrassed and have an
insouciant charm and candor that comes from lack
of self-awareness.  Their means of protecting
themselves from unwanted intrusion is their
parent's protection of their privacy.  Younger
children's sense of privacy is enhanced when
their parent is present during an interview.  By
the same token, the requirement of a parent's
permission to have the child interviewed serves
to protect the overly shy or emotionally
unstable child from the researcher's intrusion. 

The younger the child, the more important it is
for investigators to pilot test consent (assent)
information and surveys to determine whether
children can understand the language.  Young
children, under age 6, usually do not understand
statements dealing with hypothetical situations,
and have difficulty with quantifiers and
relational concepts.  As children mature, they
develop increased understanding of the
hypothetical or conditional.  The use of long
sentences that would be understandable to an
adult is problematic with younger respondents. 
Some guidelines for communicating with children
in survey research follow:

Use short sentences with easy words to improve
comprehension.
Avoid unnecessary clauses that complicate the
question.
Avoid use of the passive voice.
Examine the child's understanding of words.  The
interviewer might ask "Tell me what a  ..is?"
Make sure the child understands the context of
the question, perhaps by prefacing a question
with a statement like: "Remember the time when
(such and such) happened."
Avoid asking a young child "why" they did
something, which the child will likely perceive
as critical and make the child feel defensive. 
It may work better to rephrase the question as a
"what" question such as "What made you feel that
way?"
Rephrase questions to check for comprehension
when the child seems to lack comprehension.

Pregnant women

Since it is conceivable that pregnant women's
experience of crime victimization may differ
from that of others, there is clear
justification for their inclusion.  The only
regulatory issue pertaining to their inclusion
is whether their participation in any way
jeopardizes their health or that of their fetus. 
This is unlikely to happen in survey research.

Cognitively impaired persons

Although there are no regulations pertaining to
research on the cognitively disabled, there has
been considerable discussion and concern (see at
http://ohrp.osophs.dhhs.gov/, go to IRB
Handbook) about interpretation of the
regulations in their case.  The primary concern
is that persons with psychiatric, cognitive, or
developmental disorders, or persons who are
substance abusers may lack capacity to
understand what interviewers are asking them to
do or to make a reasoned decision about
participation.  Many in this population are
institutionalized, which further compromises
their ability to exercise free choice. 
Institutionalized persons may want to
participate in research to appear "rational" and
"cooperative" to those who make decisions about
their release.

There is a growing consensus among ethicists
that researches should select cognitively
disabled persons as subjects only when the
research bears some relationship to their
situation.  In the case of the NCVS, the choice
of those cognitively disabled persons who are
competent to respond to the survey may be highly
appropriate since they may be particularly
vulnerable to certain forms of victimization. 
However from a researcher's point of view the
issue is whether they are competent to respond
accurately to the survey.  This underlines the
more fundamental issue that the interviewers,
the investigators, and the IRB need to work
closely with persons who are knowledgeable about
and experienced in working with cognitively
impaired populations to decide whether and how
to include them in the research.

Most that has been written on this topic
pertains to biomedical and pharmaceutical
research, and it is not easy to apply the same
ideas to survey research such as the NCVS. 
OHRP's primary concern is that incompetent
subjects with court-appointed legal guardians
provide consent in a responsible fashion. 
Persons deemed incompetent to decide about
participation probably would also be incompetent
to participate in survey research.  Conceivably,
family members could provide a more accurate
account of the crime victimization of
cognitively impaired persons.  However persons
having minor cognitive impairment who are not
institutionalized might be deemed competent to
participate in the NCVS.  They might be
included, with advice and guidance from persons
who are knowledgeable and experienced in
administering similar instruments to cognitively
impaired individuals.

Elderly persons

The elderly are a heterogeneous group, not
usually in need of special protections, except
under circumstances of cognitive impairment and
institutionalization.  However investigators
sometimes fail to include them in research
because of difficulties in recruiting them. 
Older persons tend to avoid events that
interrupt their daily routine, are inconvenient,
or do not directly benefit them (Sachs and
Cassell, 1990, p. 236).  They are more likely
than younger persons to drop out of studies so
that investigators may need to recruit more
elderly to account for this.  Elderly persons
who live alone tend to have warranted fears of
scam artists and others who would harm them. 
The use of gatekeepers such as directors of
senior centers may provide useful assistance in
identifying the investigator as someone it is
safe to associate with.  Elderly persons who
live with younger relatives have a different
problem   keeping parts of their life private
from younger members of their family. 
Researchers need to recognize this problem.  The
interviewer should ensure that the interview
takes place in a private setting and that they
can conduct a phone interview under conditions
of privacy at the elder's end of the line.

Even those elders who are well educated and have
kept abreast of news and changes in our culture
may use a somewhat different vocabulary than
younger cohorts and may be unfamiliar with some
new concepts.  The interviewer needs to be
sensitive to these possibilities and be prepared
to rephrase questions.

Elders may have hearing and vision problems that
interfere with responding to a survey.  Hence
elders may require more time, large-print
material, and patient explanation until the hard
of hearing are able to accurately understand.

The very elderly, on average, are far less
educated than younger cohorts.  Those who have
had little formal schooling are not test wise. 
Some of the formats of written surveys such as
item ranking, Likert scales, and multiple choice
items are foreign to them, hence difficult for
them to use (Levine, 1982).  Generally,
education, health status, and inadequate
communication about the research, rather than
age, are responsible for lack of comprehension
and recall (Sachs and Cassel, 1990, pp. 235-
236).  When interviewing poorly educated
elderly, interviewers should use a more
conversational approach to yield more
satisfactory responding.  The wide-ranging
demographic differences and corresponding
response differences underline the importance of
adequate stratified sampling, with oversampling
of those segments of special scientific interest
to the project.

Minorities

The inclusion of racial and ethnic minorities in
national surveys is vital to the
generalizability of the results.  However
minority groups frequently have a negative
perception of research, and it can be difficult
to recruit minorities because they fear lack of
confidentiality.  Focus groups within minority
communities can provide useful communication
between investigators and community members.  In
that context, researchers can explain the aims
and process of the research and the safeguards
to confidentiality.  Investigators can learn the
perceptions and fears of community members,
correct erroneous perceptions, and allay fears. 
A second reason to do pilot work within the
relevant minority communities is to learn about
possible linguistic problems.  Often it is not
simply a matter of obtaining an accurate
translation from standard English to another
standard language.  The combination of dialects
and variants can make standard translations
inadequate for accurate communication.  For
example, immigrants from Mexico may speak a
variant of Spanish according to their home
region, and the Spanish of Mexico itself differs
from the Spanish of Central America.
Members of racial or ethnic minorities in the
United States are relatively more likely to have
problems of transportation and child care to
participate in studies, especially when repeated
interviews are required.  Interviewers should be
sensitive to these problems and be prepared to
offer solutions.

Interviewers also need to be sensitive to
cultural norms of the respondents.  Researchers
should include  members of the given cultural
group on the research team to help ensure the
survey's success.  Investigators should consult
with other researchers, clinicians, or outreach
workers who have worked with the given cultural
group in a given location.  Federal Regulations
recommend that IRBs reviewing research involving
racial or cultural minorities have a
representative of that group on the IRB or
invite a consultant from that group to assist
with review of the protocol.

Students, employees, and institutionalized
persons

Issues of coercion and confidentiality arise
with respect to these groups of persons.  Will
their gatekeeper, including their employer,
teacher, physician, or jailer, pressure them to
participate?  Will researchers keep their
responses confidential and not disclose them to
the gatekeeper or others?  Do the respondents
perceive that they will win favor within their
institution by participating in the research? 
Is recruitment truly a voluntary process?  As a
safeguard, are respondents given every
opportunity to refuse to participate during the
consent procedure, and to discontinue their
participation at any point in the procedure?  If
they do not complete their participation in the
research, is this fact kept confidential from
their gatekeepers?

Economically or educationally disadvantaged
persons

Economic and educational disadvantage tend to go
together, but create different problems. 

The economically disadvantaged person is easily
recruited when large financial incentives are
offered, and their advocates would argue that
large financial incentives may be appropriate. 
However IRBs are wary of the incentive that is
so large that it is coercive.  Moreover, if
respondents perceive that the financial
incentive is contingent on completion of the
interview, there is the double threat of
coercion and lack of candor.  Noncontingent
financial incentives are more beneficial in all
respects, and they also are more effective in
recruitment (Singer, Groves, and Corning, 1999).

Economically disadvantaged persons may require
financial incentives that are higher than those
for economically secure individuals.  These
incentives are likely to include costs of child
care and transportation.

Middle-class interviewers may be ineffective at
establishing rapport and communicating
effectively with poor people.  Some researchers
employ and train as interviewers persons who are
demographically similar to the respondents.  For
example, Kim (1997) used poor women to survey
poor women in an evaluation of federally funded
job training programs to determine whether job
placement rates and earnings of program
participants are higher than those of
nonparticipants.  Kim incorporated feminist
approaches, including asking open-ended
questions rather than multiple choice, that
resulted in a somewhat more qualitative set of
responses.  The richness of detail provided
perspectives that would otherwise have been
overlooked.  Kim reports that the approaches she
used reduced interviewer bias, improved response
rates, and facilitated trust in answering
sensitive questions.  The poor women trained as
interviewers learned about scientific inquiry
and earned money.

While educational disadvantage tends to be
associated with economic disadvantage, that
association is not always present.  The
respondent who seems not to understand questions
or instructions and who cannot respond
appropriately in test-like formats may simply be
inexperienced with school-type activities.  The
respondent may be perfectly capable of
describing the relevant experiences and
attitudes, but not in the formats presented. 
More seriously, the respondent may be
illiterate.  Many apparently middle-class people
are illiterate but have developed considerable
skill at faking literacy.  The interviewer needs
to be sensitive to this possibility and be
prepared to switch to an oral format that allows
the respondent to answer in a more
conversational and open-ended way.

8.  Efforts to minimize refusals to participate
in sensitive surveys 

A major ethical value underlying survey research
is that it yield valid and useful knowledge   a
goal that is unattainable unless respondents
participate candidly.  However most of the human
subject issues raised by IRBs and the Common
Rule concern the protection of human subjects,
not their willingness to participate and be
candid.  Consequently IRBs sometime reject
approaches that seem to provide "too much"
motivation to participate.  For example,
although it is well established that street
people, particularly drug addicts, will not
participate in research unless they are paid in
cash, some IRBs do not want to approve this
practice because such respondents will use the
money to buy more drugs.  IRBs do not want the
monetary incentives to be more than the
individual would ordinarily earn for that amount
of work time.  Thus airline pilots who are
subjects could be paid far more to participate
in a survey than a poor person, a notion to
which many poor subjects and their advocates
object.  
There are two kinds of efforts: efforts to
induce people to agree to participate in
sensitive surveys, and efforts to induce them to
give honest answers to sensitive questions.

Efforts to induce participation

There are two factors that consistently and
substantially increase participation: payment of
monetary incentives and number of contacts. 
Regarding number of contacts, the standard
practice is to recontact nonrespondents up to
three times.  By the third contact,
investigators get response rates that are
usually at least 30% higher than they would have
gotten with only one contact.  This procedure is
viable even with mailed anonymous surveys. 
Researchers include a postcard containing the
respondent's name with the survey that the
respondent is to drop in the mail at the same
time the survey is mailed.  Investigators send
repeated mailings only to those who have not
mailed their postcard.  The postcard could also
be used by the respondent to indicate which
incentive they want in return for participation.

The effects of monetary incentives are more
complicated and interesting.  Church (1993)
performed a meta-analysis of the experimental
literature (38 studies) on the effects of
incentives in mail surveys.  He classified
incentives into two categories: whether they
were monetary or non-monetary, and whether they
were offered with the initial mailing or made
contingent on the return of the questionnaire. 
His conclusions were that:

Prepaid incentives are more effective than
promised incentives, such as incentives that are
contingent on completion of the survey.
Prepaid monetary incentives are more effective
than gifts offered with the initial mailing.
Response rates increase with increasing amounts
of money
The offer of contingent (promised) money and
gifts does not significantly increase response
rates.

Church's study leaves unanswered the question of
whether the effects of incentives on response
rates vary by mode of interviewing.  Could
Church's findings be replicated with face-to-
face or phone interviews?  Singer et al. (1999)
performed a meta-analysis of 39 experiments and
used the following independent variables: amount
of incentive, type (gift or money), timing
(before the interview or promised and given
afterward), and burden (whether the interview
was longer than an hour or if it included a
diary, test, sensitive questions, or panel
study).  In addition to their main dependent
variable, response rate, they also examined
quality of data (nonresponse and number of words
in response to open-ended questions), cost per
interview, and relationship of response to
incentives with demographic variables.

Singer et al. essentially replicated Church's
mail survey findings with telephone and face-to-
face survey findings.  Moreover they showed that
incentives are effective in increasing response
rates in both low- and high-burden studies, and
for fresh respondents, panel respondents, and
those who have refused to respond previously. 
However they found that the effects of
incentives are relatively modest.  Some of the
details are pertinent:
Respondents preferred prepayment to promised
payment even in face-to-face interviews.
The effects of incentives are linear within the
limits of the monetary incentives offered.  The
money offered varied from $1 to $100; 60% of
incentives were less than $10; mean value was
$11.39.
Gifts were significantly less effective, even
controlling for the cash value of the incentive.
It was expected that high-burden surveys --
surveys lasting more than 1 hour; surveys with
ancillary tasks such as a test or diary, surveys
with repeated or panel testing --would benefit
more from high incentives than would low-burden
surveys, but only an insignificant interaction
was found.
When low-burden phone or face-to-face interview
studies were analyzed separately, they found
that incentives had the same effects.
When studies involving a diary, test, or other
self-administered instrument were excluded, the
effects of incentive remained significant.  
The higher the response rate to the no-incentive
condition, the smaller the effect of an
incentive.   
About one-third of the studies analyzed were
unpublished, and Singer et al. compared their
findings with those of the published studies. 
They found no differences.
Incentives tend to yield better quality
responses.
Paying an incentive tends to produce higher
numbers of respondents in demographic categories
such as low income or nonwhite respondents that
might otherwise be underrepresented in sample
surveys.

Singer et al. note that an important question
that remains unanswered is whether the costs of
surveys with incentives is cost effective in
relation to the savings, including fewer calls
and mailings to respondents.   

This elegant analysis also left unanswered the
question of whether respondents would regard it
as inequitable to offer a monetary incentive to
non-respondents.  Subsequently, Singer, Groves,
and Corning (1999) studied whether cooperative
respondents would perceive the use of incentives
to convert refusals as inequitable, and whether
those who learn of the practice will be less
willing to participate in future surveys. 
Singer et al. found that survey respondents are
sensitive to issues of fairness in the
distribution of incentives, but these issues are
not especially salient and are not among the
factors that motivate survey participation.

Efforts to evoke answers to sensitive questions

A central concept for understanding how to evoke
answers to sensitive questions is the "foot-in-
the-door" technique (discussed in section 2). 
Respondents who are first asked innocuous, then
mildly sensitive, and then very sensitive
questions will cooperate and answer such a
sequence of questions. However they would refuse
to answer the most sensitive questions if such
questions were asked in isolation or near the
beginning.

A second major concept has to do with obtaining
honest answers to sensitive questions.  This
problem includes self-report bias, in which
respondents underreport disapproved,
embarrassing, or illegal behavior, and
overreport socially approved behaviors.  Persons
tend to present information about themselves in
a way that they believe would enhance their
worth to the interviewer.  Sudman and Bradburn's
(1982, chapter 3) classic list of approaches to
asking sensitive questions includes both of
these concepts.  They describe ways to
manipulate the context or presentation of
questions to lead from general/neutral to
specific/sensitive, and ways to create a more
permissive frame of reference.  Current research
has sought to refine these powerful techniques
through experimentation.

A third major concept has to do with the
respondent feeling respected and understood. 
Respondents may engage in self-report bias, lie,
or refuse to answer sensitive questions if they
feel badly about answering a sensitive question
honestly.  These problems are exacerbated when
respondents feel that an "outsider" is poking
insensitively into their business.  Cultural
sensitivity can sometimes help solve this
problem.  Interviewers can be matched with
respondents, with respect to life experience,
gender, ethnicity, dialect, or whatever other
demographic factor may be relevant.

Researchers have tried various solutions to
these problems, and there is a lot of literature
about these issues as they pertain to survey
research.  Three kinds of literature are
reviewed here:

Research on data collection formats, such as
computer-assisted self-administered surveys and
sealed booklet surveys, which reduce self-
consciousness because the respondent interacts
privately with a computer, not with the
interviewer.
Research on better ways to ask sensitive
questions.
Research on interpersonal factors, including
effects of presence of third parties at the
interview, the data collection format, and
development of better ways to ask questions.

Data collection formats

A promising way to obtain answers to sensitive
questions is through self-administration of
these questions.  A large number of studies
demonstrate that self-administration via
computer increases levels of reporting compared
to administration of the same questions by an
interviewer.  Respondents are apparently
reluctant to admit to an interviewer that they
have engaged in illegal or otherwise
embarrassing activities. 

Tourangeau and Smith (1996) reviewed many of
these studies and observed that the effects of
the computer are no more desirable than other
kinds of self-administered survey.  Moreover
with a self-administered computer or written
questionnaire, persons with poor reading skills
will have difficulty comprehending the
questions.  Tourangeau and Smith propose that
audio computer-assisted self-administered
interviewing (ACASI) may solve this problem. 
ACASI may preserve the privacy of self-
administration without requiring much respondent
literacy.  In one study, which controlled for
the novelty and other aspects of computer use,
they examined the willingness of respondents to
admit (via computer) to extremely sensitive
questions, including aspects of cocaine and
marijuana use.  They compared computer-assisted
personal interviewing (CAPI) in which the
interviewer was present, computer-assisted self-
administered interviewing (CASI), and ACASI.  

With CAPI, the questions appeared on the
computer screen, the interviewer read them to
the respondent, the respondent answered the
interviewer, and the interviewer then entered
the response.  

With CASI, the respondent interacted directly
with the computer after the interviewer gave
instructions and helped the respondent get
started.  With each question, the respondent
receives a reminder at the top of the screen on
how to back up to the prior question, go on to
the next, or refuse to answer a question.

With ACASI, the information displayed on the
screen is simultaneously played via earphones. 
With both the CASI and ACASI conditions, the
interviewers were instructed not to look at the
screen while the respondent completed the
question, but to listen for any beeps indicating
the respondent was having problems with the
computer. 

Tourangeau and Smith found remarkably large
differences in reporting of illegal drug use and
multiple sexual partners, with the largest
number of instances reported with ACASI and the
smallest number of instances reported with CAPI. 
Others have also found that ACASI is superior to
other methods.  Moreover it can be used in a
variety of settings, including homes.  For
example, Lesser and O'Reilly (1997) reviewed
established strategies, self-administered
questionnaires, and indirect questioning
techniques to examine their effect on
willingness to report stigmatizing behavior. 
They discuss ACASI extensively, describing its
features and the results it has yielded. 
Similarly, Kissinger et al. (1999) report
positive results using video-enhanced computer-
assisted interviews and ACASI.

A "low tech" approach to achieving privacy is to
administer the interview using a sealed booklet
which the respondent fills out in the presence
of the interviewer, providing anonymity to the
respondent.  Compared to the face-to-face
interview, this method produces greater
willingness and accuracy of answering in
response to sensitive questions.  However it
does not solve the problem of respondents having
poor reading skills (Makkai and McAllister,
1992).

Development of better ways to ask sensitive
questions

A well-documented finding of experimental
cognitive psychologists is that the way a
question is framed will affect the way it is
answered.  Willis (1997) described a variety of
developments designed to reduce response error
using cognitive laboratory techniques in
developing a survey.  He described ways in which
investigators can examine the thought processes
of subjects in relation to the various ways
questions are framed.  The variables studied
include the way respondents are introduced to
the interview, if researchers test for
comprehension, how researchers avoid
embarrassing respondents, the effects of social
cues from the interviewer, use of demographic
information in formulating questions and
interpreting responses, and exploration of what
makes questions sensitive and for what kinds of
respondents.

Research on illegal or embarrassing behaviors
has systematically examined the old "everybody
does it" approach developed by Kinsey et al.
(1953).  "Counterbiasing" means framing the
question so that the particular behavior is made
to seem relatively frequent, normal, or
unremarkable.  Researchers have studied
counterbiasing in various contexts and found
that it is effective in producing more
admissions of socially undesirable behavior. 
Raghubir and Menon (1996) and Tourangeau and
Smith (1996) describe counterbiasing methods in
a variety of settings.

Interpersonal factors

The research on the effects of interpersonal
factors illustrates that the degree of
sensitivity of the issue and contextual factors
are critical to the results.  

Johnson and Moore (1993) examined the effects of
interviewer gender in a telephone survey of
attitudes regarding sale and consumption of
pornography.  They found that interviewer gender
effects were not significant.

Smith (1997) examined data from the 1994 General
Social Survey (GSS) to determine whether
presence of a third party such as a spouse or
child effects responses to questions.  For
married respondents, the presence of a spouse
did not effect answers to 15 questions about
marriage and sexual matters.  Among 13 questions
about values, answers were scarcely effected by
presence of a child, with one exception: 
Respondents appear less approving of premarital
sex when a child age 6 or older is present. 
Self-reported items on health were somewhat
affected by the presence of others.  Overall the
impact of third parties on survey responses was
rare and small.  Smith offers a host of good
suggestions on ways to gain a better
understanding of third-party effects.  Given the
similarity between his work with the GSS and the
NCVS project, his comprehensive discussion of
possible effects of third-party presence in such
surveys would no doubt be of interest to BJS and
Census.

Darrow et al. (1986) examined a series of
studies of the responses of homosexual men to
sensitive questions asked by physicians to learn
the effects of place of interview and gender of
interviewer.  The difficulties of adjusting
results to avoid confounding may have weakened
the findings.  However the conclusion was that
the gender of interviewer and place of interview
seemed to have little influence on the
respondents.  The authors speculate that the
motivation to gain accurate answers and medical
assistance may have overridden any deterrents to
responding.
Kim (1997) found that having poor women
interview poor women, using an open-ended
interview format, evoked more detailed
information and increased willingness to answer
questions (see section 7).

The study by Barker and Cooper (1996) is another
example of how little difference sensitive
questions make in most survey research contexts. 
They included a sensitive question about sexual
health in half of the 600 "lifestyle"
questionnaires sent to individuals in Solihull,
West Midlands.  After 3 weeks, nonrespondents
were sent a reminder and a second questionnaire. 
The response rates were virtually the same for
the "sensitive" and "nonsensitive" groups for
both the initial and the follow-up
questionnaire.  However their "sensitivity"
induction may not have been strong enough to
reveal possible effects.

9.  Survey procedures for informed consent with
special procedures for obtaining consent for
respondents under age 18

Informed consent is a primary ethical
requirement of research with human participants. 
It expresses respect for the autonomy of persons
by permitting them to make a reasoned decision
of whether to participate.  The process of
informed consent is far more than a consent form
or a one-time discussion.  Informed consent
should consist of friendly on-going
communication in which the individual is free to
raise questions throughout the research process. 
In repeated-measure research such as the NCVS,
the initial consent process may seem perfunctory
to the respondent.  As questions arise in the
respondent's mind, the real informed-consent
communication can take place.  It is appropriate
that the interviewer be prepared to engage in
the on-going communication required to continue
to inform the respondent as appropriate.  

Regulatory requirements

The informed consent process is governed quite
strictly by federal regulations (see 45 CFR
46.116(a)).  Although it is intended as a
respectful communication process, it is often
treated as a bureaucratic formality by
investigators seeking to conform to regulatory
requirements.  

Informed consent is legally required unless the
following four conditions are met:

The research involves no more than minimal risk.
Waiver or alteration of the process will not
adversely effect the rights and welfare of the
subjects.
The research could not practicably be carried
out without the waiver or alteration.
When appropriate, subjects are provided with
additional pertinent information after they have
participated in the study.

Documentation (45 CFR 46.117) involves written
consent information that the subject signs, and
the subject  receives a copy of the consent
information.  Subjects tend to confuse the
signed consent form with informed consent.  This
confusion does not make for good communication
or a friendly process.  It is possible to obtain
informed consent that meets the criteria set
forth in the federal regulations and to create a
friendly, open, on-going communication process. 
However the formal criteria do not foster on-
going communication.

As discussed in section 7, many individuals,
particularly members of minority populations, do
not want to sign documents but would participate
in surveys otherwise.  Fortunately, written
documentation may be waived if (a) the
documentation is the only link that identifies
the subject with sensitive information, or (b)
the research presents no more than minimal risk
and involves procedures that do not require
written consent when performed outside of a
research setting (45 CFR 46.117).  Most survey
research meets one of these criteria.  

The regulations governing informed consent were
written for biomedical research.  Issues that
might be important to a respondent in a survey
are not "risks and discomforts" or "alternative
procedures or courses of treatment," but rather
what will the interviewer ask, how long the
survey will take, and how will investigators
keep identified data confidential.  The
adaptation of regulatory requirements for
purposes of survey research has required
ingenuity.

In a perfunctory effort to comply with the
federal regulations, many consent forms are
written in such a legalistic, vague, or
specialized (scientific) language that they are
incomprehensible to most respondents.  It is
important that researchers keep the
communication process of informed consent
understandable and engaging, and that they
answer the questions that are important to the
respondent.  Interviewers should remember that
informed consent is a two-way conversation, and
a cognitive process that properly involves
comprehension, trust, consideration, and
autonomous decision-making on the part of the
participant.

When survey research is conducted with minors,
parental permission and documentation of that
permission, as well as assent of the minor, are
normally obtained.  However IRBs may waive
parental permission and documentation under the
conditions in 45 CFR 46.117.  While the legal
requirements may be relaxed, ethical and
practical considerations would still require the
on-going communication process of informal
informed consent.  It is especially important
that the interviewer explain the research to the
child in age-appropriate terms the child can
readily understand.

Informed consent as practiced in survey research

When survey researchers attempt to follow the
formal requirements for informed consent a
number of questions often arise:

How can informed consent foster respect for
privacy in survey research?
How much information do subjects want to
receive?
How much and what kind of explanation are
appropriate in obtaining children's assent?
How can the researchers make a child understand
complex details?
When complex issues need to be explained, such
as confidentiality and the limits to which it
can be assured, how can the interviewer be sure
the respondent understands?
How can a researcher conduct and document
consent in Internet surveys?

Consent and privacy

Informed consent is supposed to be a
transaction, contract, or agreement between the
investigator and the respondent.  Moreover it is
supposed to be on-going, two-way communication
in which the participant can renegotiate the
agreement as needed.  There are various reasons
why the respondent may want to reopen the
conditions of the research.  For example, a
survey that is conducted in a face-to-face
interview or by phone may take longer or involve
more unwanted experience than the respondent
anticipated when initially consenting to
participate.   

Respect for privacy means:

Giving persons freedom to pick and choose the
time and circumstances under which facts about
themselves are disclosed,
Permitting them to share or withhold from others
their attitudes, beliefs, behavior, and
opinions, and
Permitting them to reject information they do
not want to receive.  

All three of these conditions are pertinent to
NCVS interviews.  For example, setting up a
phone interview about crime victimization
entails some agreement about a convenient time
and place and the respondent's willingness to
participate.  Once the interview begins, the
respondent may feel constrained to answer
questions that seem invasive, or that are being
asked after someone else has entered the room
and can overhear the conversation.  The
respondent may feel the questions to be
upsetting.  When this point is reached, the
interview is damaged.  A better procedure is to
make sure the interview occurs under
circumstances that are truly comfortable for the
respondent, and for the interviewer to be
sensitive enough to realize that the respondent
would rather not answer or would like to resume
the interview later.  Such consideration on the
part of the interviewer may seem costly in the
short run, but in the long run it means that:

the relationship of mutual trust and respect
between respondent and interviewer is maintained
and strengthened.
the likelihood that the respondent will remain
in the study for the full cycle is increased.
the ease of scheduling future interviews is
enhanced.
the candor and mindfulness with which the
respondent answers questions is increased.
a smaller sample that produces high-quality data
can be used in place of a larger sample that
produces flawed data.

How much information do respondents want?

Since the inception of IRBs, social and
behavioral scientists have pointed to the
importance of providing reasonable amounts of
information as opposed to overwhelming
respondents with lengthy and complex consent
statements.  Singer and Frankel (1982) studied
the effects of lengthy and detailed consent
compared to simpler consents and found no
significant differences in response rate or
quality (see section 11).  Singer (1993)
reviewed the literature on informed consent in
surveys, most of which focuses on the effects of
promises of confidentiality.  While promises of
confidentiality are marginally important to
respondents in sensitive research, they are
counterproductive in nonsensitive research.

Investigators who conduct social and behavioral
research observe that the formal content of the
consent is largely ignored.  Respondents focus
on whether they like and trust the researcher. 
Some physicians have remarked that physicians
who have good communication skills and a caring
manner don't get sued.  The formality of
informed consent has little or nothing to do
with the way patients feel about their
treatment.  

Guidelines for obtaining children's assent

In research on children, it is particularly
important to regard informed consent as a
friendly, understandable, engaging communication
process.  Section 7 includes guidelines for
talking to children to obtain their assent. 
Researchers should present the information in a
conversational manner that is responsive to the
child's questions and comments.  

IRB websites contain some good examples of
assent statements designed for children.  The
Social and Behavioral Sciences IRB at the
University of Chicago has an excellent example
(http://humansubjects.uchicago.edu/sbsirb/).

Beyond oral communication, it may be useful to
show children what they will be doing, and
possibly show them a videotape of another child
participating in the procedure.

Ensuring comprehension of complex issues

The rise of the use of computers in self-
administered survey research has intriguing
possibilities for providing informed consent
information in a tutorial context.  Although
this procedure has been most seriously
considered in the case of risky biomedical
research, it has special potential for survey
research involving computer-assisted self-
administered surveys.  In the case of surveys
conducted on the Internet, the consent process
can readily be administered on-line at the
outset as an automated tutorial, so that
respondents can not advance to the survey until
they demonstrate comprehension of the consent
statement.

10.  Effects of signed consent on response rates
and other aspects of conducting a survey or
other study

In 46.117, " Documentation of Informed Consent,"
the Common Rule sets forth the requirement that
the interviewer read the consent form to the
subject or a legally authorized representative
or give the form to the subject to read, and
that the subject or the representative sign the
form.  A number of alternative procedures are
also set forth in the case of illiterate
subjects or subjects who do not wish to sign a
document for some reason.

Because there are various subcultures in the
United States that are disinclined to sign
documents, the general requirement of signed
consent poses complications for research that
depends on random sampling, such as sample
surveys.  

Regulatory issues

The issue of signed consent does not arise in
some survey research for two reasons:

Exemption of anonymous adult surveys from the
regulations.  Research involving survey or
interview procedures with adult subjects is
exempt from the Federal Regulations unless the
information obtained is recorded in such a
manner that the subjects can be identified and
the data could place the subjects at risk of
criminal or civil liability or damage the
subjects' financial standing, employability, or
reputation (45 CFR 46.101(b)(2)).  However some
IRBs review all surveys even if they meet the
criteria for exemption.
Exemption from signed consent.  An IRB may waive
signed consent, even when surveys are not
anonymous, when the principal risks are
connected with breach of confidentiality
concerning the subject's participation in the
research   such as in the study of sensitive
topics   and the consent document is the only
record linking the subject with the research (45
CFR 46.117(c)).  An IRB may waive signed consent
or other elements of the consent procedure when
it finds that the research involves no more than
minimal risk to the subjects and involves no
procedures for which written consent is normally
required outside of the research context.

It is important to note that whenever an IRB
exempts a survey from signed consent, including
the consent of the primary or secondary subject,
the IRB must record its analysis of the ways in
which the protocol meets the above criteria in
the documentation of its decision.

In the case of high-risk interviews in which the
only link to the respondent might be the signed
consent, researchers can use other procedures
such as witnessed consent.  For example, a
researcher interviewed a 16-year-old concerning
his gang membership and his decision to leave
the gang.  Because his parents did not know
about his gang involvement, researchers waived
parental permission.  Because his decision to
discuss the gang and to contemplate leaving it
could be very dangerous to him, the interview
was conducted out of town at a small restaurant
during non-meal hours.  A colleague of the
interviewer sat in an adjacent booth; overheard,
witnessed, and documented the oral consent; and
served as lookout in case a likely gang member
entered the restaurant.

Background considerations

It is well-documented that there are many groups
within the United States that are very wary of
participating in research and signing any
documents, especially consent forms connected
with a government research project.  These
conclusions are drawn from many sources, most
notably (a) the U.S. Census Bureau which must
contend with problems of undercounting among
those populations that are skeptical of being
enumerated, and (b) cultural anthropologists who
focus primarily on those American cultures that
are politically, educationally, or economically
marginal.

The problems experienced by the U.S. Census
Bureau are particularly relevant to this
discussion.  Census has had a long tradition of
maintaining the confidentiality of its data, but
the number of people willing to be enumerated
has declined.  The proportion of non-white
individuals who are unwilling to be enumerated
is about triple that of white individuals. 
Turner (1982) describes the findings of several
key studies of public attitudes toward being
identified in surveys, including studies by the
American Statistical Association, the National
Academy of Sciences, and the U.S. Census Bureau. 
Since that report, the undercounting situation
with respect to minority populations has
worsened.

Cultural anthropologist Murray Wax, in his
testimony before the National Bioethics Advisory
Commission (2000), poignantly described the
challenges facing cultural anthropologists who
seek to study unassimilated Hispanic and Indian
cultures.  If their IRB insists on signed
consent, their research is rendered impossible. 
The reasons for refusal to sign documents
varies.  Among many Native Americans, there is a
long history of losing land by signing documents
they do not understand.  Among members of
populations who are conducting underground
commerce, there is fear of identification and
prosecution.  Among members of many non-Western
cultures, there is the belief that a person's
word is what counts, and that requiring marks on
a piece of paper (the signature or X) is
meaningless and insulting.

Both Singer (1978) and Trice (1987) found that a
significant number of respondents refused to
participate in a survey if required to sign the
consent form, but would participate otherwise. 
There has been no recent research on the effects
of signed consent on response rates.  However,
if more current data were desired, specifically
with respect to the NCVS, Census could readily
research this.  One approach would be to
randomly assign a small proportion of each
cultural subgroup studied to a condition in
which they are asked to sign a consent form. 
The results of this condition could then be
compared with the matched non-signing group with
respect to refusals, and perhaps also with
respect to the quality (detail) of responses and
the distribution of crime victimization events
reported.  

The NCVS might be exempt from signed consent
under the Common Rule.  While some of the
questions may be sensitive insofar as asking
respondents to recall victimization, they do not
involve more than minimal risk except for a very
few cases where there may be risk of some
emotional upset.  
.11.  Researching ethical questions

This report was written to provide specific
answers to pertinent ethical questions, and to
provide an overview of the many highly complex
ethical questions to which the answer is "It
depends ."  Typically, the tough ethical
questions pit two competing kinds of good
against one another, and usually each kind of
good brings with it competing bad side-effects. 
For example, should the informed consent be so
comprehensive that it answers every question any
participant might have, or would this be so long
and tedious a document that respondents would
tune out and be less well informed?  Would
comprehensiveness destroy or deter
comprehension?  

The research organization and its IRB quickly
learn that each ethical dilemma is a bit
different because research contexts, resources,
and scientific, social, and regulatory
environments differ.  Most ethical and
regulatory questions are resolved through
reasoned discussion by the researchers and IRB,
who examine the pros and cons of alternative
approaches in detail.  The decision makers seek
the solution that seems -- to them -- to best
fit the situation.  The IRB may weigh ethical
and regulatory decision criteria above
scientific and practical criteria, while the
researchers may rank these decision criteria
otherwise and may persuade the IRB to place more
weight on certain scientific and practical
considerations.  In accord with regulatory
requirements, the IRB summarizes in its minutes
the discussion, its reasoning, and the grounding
of that reasoning in the regulations and the
Belmont principles (beneficence, respect, and
justice), and finally its conclusion.  At this
point, the decision of the IRB is in compliance
with the Common Rule, and the researchers must
comply with the decision.

There are dangers to some of the assumptions
that IRBs and researchers may bring to their
reasoned discussions as the following examples
illustrate.  During the last 25 years many
social and behavioral scientists have expressed
certainty that requirements of informed consent
would destroy their ability to conduct valid
research, but most of these views have proven
fallacious.  Similarly, many IRBs have insisted
on individual, and even signed, informed consent
of subjects in cultures such as Native American
tribes, where decisions are made at a tribal,
not individual, level, and where signing
documents is regarded as insulting or dangerous. 
For examples of cultures that do not regard
autonomy of the individual or signed consent as
acceptable, see Marshall (1992) and Wax (2000). 
IRBs are required to have at least one community
member who might be better able to speak for at
least one other culture than can the rest of the
IRB, for example, a community member who is an
experienced school teacher can speak for the
culture of the local schools.  Some researchers
are quite familiar with the cultures they study. 
However there are many instances in which IRBs
and researchers do not know enough about what is
"out there" to make sound ethical decisions.

Although ethics is a normative discipline, the
ethics of survey research raises many questions
that are empirical and methodological.  Ethics
requires that researchers obtain children's
informed assent to participate; but does not
tell us what kinds of information children can
understand or what kinds of decisions they are
competent to make at a given age.  Ethics
requires that researchers respect
confidentiality of information obtained from
respondents, but does not tell us whether
respondents believe promises of confidentiality
or whether such promises make a difference in
their willingness to participate candidly.  As
this literature search reveals, major survey
research organizations   Survey Research Center
of the Institute for Social Research, University
of Michigan; National Opinion Research Center,
University of Chicago; the U.S. Census Bureau  
carry out continuous programs of research on
ways to improve their research methods.  Many of
these programs are stimulated by changes in the
ethical or regulatory environment of social
research.   

In their continuing quest to improve ethical and
methodological aspects of the NCVS, BJS and
Census will undoubtedly face many empirical
questions, some of which were raised in this
report.  Is the NCVS designed to evoke the most
accurate responses from young teenagers or would
a somewhat different version work better?  Does
signed informed consent affect willingness to
participate or to answer sensitive questions? 

Survey researchers can use several approaches to
answer empirical questions.  Some useful
approaches are: the experiment within a study or
as a pilot test prior to a study, the focus
group to explore reactions of respondents to
aspects of the intended survey and to generate
new hypotheses to be tested, the ethnographic
study of one's research populations, and the
study of meta-communication within the research
process.  A brief outline of these approaches
follows.

The experiment within a study

Researchers can add one or more experimental
conditions to some aspect of the study, and
examine the effects of the variations in
relation to one or more dependent variables. 
Here are a few examples:

The experimental conditions may be integral to
the survey, such as the effects of anonymity or
various kinds of confidentiality.  Investigators
might try different wordings of sensitive
questions and different ways to jog subjects'
memories.  Researchers might perform these
experiments in pilot tests or build them into
the main study.

Sometimes such experiments are not intended to
yield generalizable knowledge about survey
research, but rather to provide information
about the particular research issue.  An example
of such an experiment follows.  Sieber and Saks
(1989) mailed a survey to all U.S. and Canadian
psychology departments that asked, essentially,
whether departmental subject pool practices were
in keeping with psychologists' code of research
ethics and with the federal regulations of human
research.  Half of the respondents were asked to
indicate the name of their university.  Was the
response rate or the admission of unethical or
illegal practices equal for the two groups?  Can
either group be trusted to tell the truth? 
Clearly, anonymity had an impact, but not in the
way expected.  Response rate was unaffected, and
there were only slightly more admissions of
dubious practices by anonymous respondents. 
However all admissions by identified departments
were accompanied by extensive rationales
justifying their behavior.  The profile of kinds
of ethical improprieties was similar for the two
groups.  The survey had a 90% response rate. 
The results of the survey and the experiment
within it indicated that departments were
mindful of the ethical implications of their
policies, sensitive or defensive about their
breaches of ethical conduct, but basically
honest in their responses to the survey.  This
is an example of an experimental result that
probably could not be meaningfully generalized
to other contexts but that provided additional
information about both the ethical sensitivities
of the respondents and the validity of their
responses.

The experimental manipulation might precede the
research itself, such as the mode in which
researchers recruit subjects (for example
letter, phone, or e-mail) the amount or kind of
incentive researchers offer for participation,
or the way researchers provide informed consent
(for example individual verbal discussion, group
discussion, pamphlet, videotape, or computer-
assisted instruction).  One prevalent idea that
has not been reported yet in the literature is
to present informed consent information via
computer-assisted instruction when the research
involves risks that are not easily understood. 
The subject would be tested, via the computer,
on the information that the interviewer has
presented, and not allowed to proceed until able
to correctly answer questions about the informed
consent process.  The program then asks whether
the respondent consents to participate. 
Researchers would electronically document the
entire procedure for each subject.  Dependent
variables might include: willingness to
participate, willingness and candor to respond
to individual questions, satisfaction with the
experience of participating, and how much the
subject knows about the study right after
participating.

The experimental manipulation might be in the
technology of the survey itself.  The survey may
be administered in a face-to-face interview,
web-based Internet survey, or computer-assisted
self-interview.  The experimental manipulation
might be the systematic variation of respondent-
researcher characteristics.  For example, does
it matter whether the interviewer is of the same
gender, ethnicity, or age bracket as the
respondent?

The focus group

The focus group is a form of qualitative
research that is best suited for generating, as
opposed to testing,  hypotheses, and for
exploring people's reactions to questions that
are somewhat new to them and for which they do
not have ready, thought-out answers.  David
Morgan (1988) suggests the following uses of
focus groups:
To orient oneself to a new field of study,
To generate hypotheses based on informants'
insights,
To evaluate different research sites or study
populations,
To develop interview schedules and
questionnaires, and
To get participants' interpretations of results.

Researchers can ask a properly organized focus
group of about 5 to 12 persons the kinds of
questions that people could not or would not
answer in a survey or questionnaire, but that
would evoke extensive lively discussion in a
focus group.  There are no right answers to
focus group questions.  The participants are the
experts; their role is to tell the researcher
such things as how they feel about a certain
issue, what they need or want, or what approach
to some activity they would find preferable or
believe would work.

For example, sociologist Benjamin Bowser (Bowser
and Sieber, 1993) sought to find out what crack
cocaine-using inner-city teenagers know about
HIV infection and safe sex, and what kinds of
sexual practices they engage in.  He hung out in
an inner-city neighborhood, got to know street
kids, and invited them to focus groups over
pizza.  He told them what he needed to know to
help kids help themselves, and asked their
advice on how to go about surveying kids who
frequent crack houses.  Their advice led him to
develop an innovative and successful survey
research approach and to achieve major survey
research findings on the risk behavior of this
population.

Although the researcher has specific questions
in mind for the group to answer, it is often
unnecessary to ask more than the first question. 
As the group takes on a life of its own, it may
raise and answer all of the researcher's unasked
questions and provide powerful unexpected
insights along the way.  It is important that
the researcher have goals in mind so that the
group can be kept somewhat on the subject; but
it is equally important that the researcher be
flexible enough to permit unexpected but highly
valuable new ideas to emerge.  At the conclusion
of the focus group, which often could go on much
longer than the leader permits, the participants
each have much clearer ideas about the topic,
ideas which they are able and willing to
articulate.  It is a common practice to give
individual respondents a questionnaire after the
focus group so that they can give their
individual responses to  questions in a short
answer or Likert Scale format.

Focus groups can be operated very inexpensively
and simply.  Commercial marketing firms may
charge many thousands of dollars for one or more
focus groups that involve one-way mirrors,
videotaping, and hours of transcribing.  However
most researchers find that an effective approach
is to involve a discussion leader and two
assistants who sit nearby and take notes on the
main ideas that are raised.  Near the end of the
focus group the assistants may summarize their
notes to the participants to ask if there are
ideas they want to add or if the note-takers got
it right.  An outstanding source of information
on conducting focus groups is Krueger (1994 or a
later edition).  A brief discussion of how to
use and conduct a focus group is found in
appendix B of this paper.

Ethnography

Issues of respect for research participants,
informed consent, risk/benefit assessment,
privacy and confidentiality, and respondents'
willingness to participate candidly and to
answer sensitive questions take on a different
character when surveying members of deviant or
marginalized populations.  Obviously each
deviant population is different and requires a
different ethnographic approach.  

Some populations of interest to researchers
conducting surveys on crime victimization are
persons whose unconventional, transitory, or
lower-status lifestyle make them highly likely
candidates for crime victimization.  These
populations include groups of homeless people,
unassimilated immigrants (legal and otherwise),
prostitutes, households of drug dealers, and
enclaves of young gay men who have migrated to
cities where their lifestyle may be more
acceptable.  If researchers wish to interview
members of such groups, they must know where,
when, and how to do so; above all, they must
know how to establish enough trust to create a
viable relationship and obtain candid answers. 

Researchers can use the knowledge of urban
anthropologists and other professionals who have
worked with the population they seek to study to
prepare their survey.  However this neither
establishes the legitimacy of the researcher to
ask for sensitive information nor gives the
researcher the level of comfort needed to work
in the environment of their respondents.  It is
well known that the personal characteristics of
a participant observer affect his or her
research practice (e.g., see Wax, 1979). 
Researchers may find it necessary to match
backgrounds of interviewer and target
population, including matching ethnicity,
gender, or language.  For example, a female
doctoral student who had once been homeless
conducted highly useful research and AIDS
outreach with homeless women who used injection-
drugs in San Francisco.  She socialized with
members of her target population for a few
weeks, after which she rented a "flop house" and
put on dinners for the people she wished to
survey.  She knew how to organize her
interaction with them so that they could avoid
police hassles.  She respected them and
conversed with them in a familiar way, and they
knew and trusted her.  Moreover, she was close
enough to them and their lifestyles that she
could evaluate their responses for candor, and
interpret responses that would not be
interpretable by persons unacquainted with this
culture and setting.

Meta-communication in the research process

It is well documented by those who perform
empirical research on the process of survey
research that there are considerable individual
differences among trained interviewers in the
results they achieve.  An interesting example is
found in the work of Singer and Frankel (1982)
who studied informed consent procedures in
telephone interviews.  Two aspects of informed
consent were varied: information about the
content of the interview and information about
its purpose.  There was a brief and a more
detailed and honest version of each.  Singer and
Frankel found that these factors made little
difference in the quality of the data collected
and the meaning of the experience for the
respondents.  By far the largest variation in
response rate to the survey occurred among
interviewers.  The more experienced interviewers
produced a higher response rate using the brief
consent procedures that they were used to, while
the less experienced interviewers produced a
higher response rate using the more lengthy
experimental procedure.   

To date there is very little understanding of
what factors enter into the success of well-
trained interviewers.  However it is obvious
that there is considerable meta-communication
that occurs between researcher and subject. 
Researchers know that tone of voice, body
language, mirroring and congruence with the
respondent, physical characteristics, room
arrangement, and distance between persons make a
difference in some situations (Sieber, 1996). 
The question is whether researchers need to be
concerned with any of these differences to
conduct survey research effectively and
efficiently.

12.  Keeping abreast of new developments and
answering questions

A growing variety of informational resources on
the ethics and regulation of human research
attest to the need for researchers to keep
abreast of new and old issues and to learn from
others.  The following resources are useful to
researchers and IRBs.

On-line resources

Relative to other areas of human research,
researchers regard survey research as relatively
risk free, and anonymous surveys that do not ask
sensitive questions are exempt from IRB review. 
Consequently there are as yet no on-line
tutorials concerned with ethics and regulations
of survey research.  In fact there are no
tutorials dedicated to social and behavioral
research; there are only tutorials for
biomedical research.  However there is
indication that Office of Human Research
Protections (OHRP), Department of Health and
Human Services, which provides guidance on
Common Rule questions, has plans to offer within
the year an on-line tutorial concerned with
social and behavioral research.

There are other ways in which survey researchers
can find answers to their questions on-line. 
Members of any IRB that is instituted in
connection with the NCVS should join the on-line
discussion group entitled McWirb
<http://www.mcwirb.org>.  Members may post
questions, share information, and learn how
other IRBs in the United States and Canada
handle issues.

Meetings 

Two kinds of professional organizations
regularly hold meetings that deal with ethical
issues in research.

The primary organization is Public
Responsibility in Medicine & Research
<http://www.primr.org>, which holds annual
meetings in Boston in December and in San Diego
in October.  It holds other meetings at
irregular intervals.  It is located at 132
Boylston Street, Boston, MA 02116; phone 617-
423-4112, FAX 617-423-1185.

The other professional organizations are
scientific societies, such as the American
Association for the Advancement of Science
<http://www.aaas.org>, American Sociological
Association <http://www.asanet.org>, and the
American Psychological Association
<http://www.apa.org>.  Their examination of
ethical issues usually occurs in the context of
their annual scientific meetings, and is far
less intense or focused than are the sessions at
PRIM&R.  
Journals

There are two journals devoted largely to
ethical issues in human research that carry
articles of concern to survey researchers.  

Ethics & Behavior is edited by Dr. Gerald
Koocher, Department of Psychiatry, Children's
Hospital, 300 Longwood Avenue, Boston, MA 02115
<http://www.erlbaum.com/Journals>. 

IRB: Ethics and Human Research is edited by
Betty Criger, and published by the Hastings
Institute.  It is of particular interest to IRB
members, research administrators, and
investigators in the biomedical and
behavioral/social sciences.  It is published by
the Hastings Center at Garrison, New York 10524,
phone 845-424-4040, fax 845-424-4545, or see the
journal index at
<http://www.thehastingscenter.org/publications>.
Two other journals that may be of tangential
interest to BJS are Scientific & Engineering
Ethics, edited by Stephanie J. Bird and Raymond
Spier, http://www.opragen.co.uk, and
Accountability in Research, edited by Dr. Adil
E. Shamoo, <http://www.gbhap.com/journals/149>. 
These journals rarely publish articles of
interest to survey researchers.

Informal local groups

NCVS researchers concerned with ethical issues
may have more interests/issues in common with
other government agencies that conduct survey
research than with researchers engaged in other
kinds of survey research.  It may prove
worthwhile to develop a consortium of government
agency IRB chairs, administrators, researchers,
and other interested members to discuss and
exchange ideas and information.

Office of Human Research Protections

The Office of Human Research Protections (OHRP),
Department of Health and Human Services, can
provide useful guidance.  OHRP is at
<http://ohrp.osophs.dhhs.gov/>.  OHRP's phone
number is 301-496-7005. 

A useful document is the OHRP publication
Protecting Human Subjects: Institutional Review
Board Guidebook, which is available from OHRP
and on-line at 
<http://ohrp.osophs.dhhs.gov/irb/irb_preface.htm>.

13.  Briefly annotated bibliography of
literature cited

American Psychological Association, Ethical
Principles of Psychologists and Code of Conduct
(Washington, D.C.: APA, 1992).
While most of this code of ethics pertains to
clinical practice and other non-research
activities, Sections 6.06 to 6.26 concern
research and are heavily relied upon not only by
psychologists but by other organizations
concerned with ethics and regulations of human
research.

A. W. Austin and R. F. Boruch, "A 'Link File
System' for Assuring Confidentiality of Research
Data in Longitudinal Studies," American
Educational Research Journal 7, 615-624 (1970).
This article describes highly sophisticated
techniques for linking files without the
possibility of discovery of individual
identities.

P. J. Barker and R. F. Cooper, "Do Sexual Health
Questions Alter the Public's Response to
Lifestyle Questionnaires?" Journal of
Epidemiology and Community Health 50, 688
(1996).
The finding that just one sensitive question did
not affect response rate leaves one to wonder
what is the threshold for making a survey too
sensitive, and hence for affecting response
rate.

David M. Bersoff and Donald M. Bersoff, "Ethical
Issues in the Collection of Self-Report Data,"
in A. A. Stone, J. S. Turkkan, C. A. Bachrach,
J. B. Jobe, H. S. Kurtzman, and V. S. Cain,
eds., The Science of Self-Report: Implications
for Research and Practice (Mahwah, N.J.:
Lawrence Erlbaum Associates, 2000), pp. 9-24.
The risks connected with self-report surveys are
discussed, pointing out that surveys can ask for
far more personal information than is available
by observation or experiment.  An anonymous
survey, requiring no IRB review or informed
consent, may deeply invade privacy and cause
much emotional upset by probing into painful
experiences.

O. Boikess, Privacy Protection for Research
Subjects: Certificates of Confidentiality,
personal communication, 2000.
This communication sets forth details of a legal
case, heard in the Supreme Court of New York, in
which the power of the Certificate of
Confidentiality was tested and upheld.

R. F. Boruch and J. S. Cecil, Assuring the
Confidentiality of Social Research Data
(Philadelphia: University of Pennsylvania Press,
1979).
This book, now out of print, might be regarded
as the most important publication on approaches
to assuring the confidentiality of social
research data.  It catalogs and describes the
many kinds of approaches to assuring
confidentiality, such as procedural,
statistical, and legal.  Though a few parts of
it would be rewritten in light of new
information, it remains a seminal work.

B. P. Bowser and J. E. Sieber, "AIDS Prevention
Research: Old Problems and New Solutions," in C.
M. Renzetti and R. M. Lee, eds., Researching
Sensitive Topics (Newbury Park: Sage, 1993), pp.
160-176.
The challenge of AIDS prevention calls for new
combinations of research tools that enable
social scientists to understand why a particular
intervention succeeds or fails.  This chapter
describes a series of approaches, including the
use of focus groups, to reconceptualize AIDS
prevention research and to improve methods and
theory in this area.

D. T. Campbell, R. F. Boruch, R. D. Schwartz,
and J. Steinberg, "Confidentiality-Preserving
Modes of Access to Files and to Interfile
Exchange for Useful Statistical Analysis,"
Evaluation Quarterly 1, 269-300 (1977).
The authors present many techniques that enable
useful data sharing and secondary analysis
without jeopardizing confidentiality of data.

A. H. Church, "Estimating the Effects of
Incentives on Mail Survey Response Rates: A Meta
Analysis," Public Opinion Quarterly 57, 62-79
(1993).
This is a useful empirical study of the effects
of financial incentives on willingness to
participate in survey research.

R. B. Cialdini, Influence: The Psychology of
Persuasion (New York: Morrow, 1993).
This important book helps us to better
understand subtle forces of persuasion that are
at work in survey research and other contexts.

J. E. Corbin, "Child Abuse and Neglect: The
Cultural Context," in R. E. Helfer and R. S.
Kempe, eds., The Battered Child (Chicago:
University of Chicago Press, 4th ed., 1987), pp.
239-255.
The authors discuss a wide range of definitions
of child abuse and neglect, and show that the
incidence of abuse and neglect vary widely
depending on definitions.

W. W. Darrow, H. W. Jaffe, P. A. Thomas, H. W.
Haverkos, M. F. Rogers, M. E. Guinan, D. M.
Auerbach, T. J. Spria, and J. W. Curran, "Sex of
Interviewer, Place of Interview, and Responses
of Homosexual Men to Sensitive Questions,"
Archives of Sexual Behavior 15, 79-88 (1986).
Their examination of a variety of physician-
patient interviews revealed virtually no
differences as a result of gender of interviewer
and location of interview.

C. B. Fisher and S. A. Wallace, "Through the
Community Looking Glass: Reevaluating the
Ethical and Policy Implications of Research on
Adolescent Risk and Psychopathology," Ethics &
Behavior 10, 99-118 (2000).
This article, based on community focus groups,
urges investigators to seek the perspectives of
teenagers and parents in evaluating the personal
and political costs and benefits of research on
adolescent risk behaviors.

J. L. Freedman and S. C. Fraser, "Compliance
Without Pressure: The Foot-in-the-door
Technique," Journal of Personality and Social
Psychology 4, 195-202 (1966).
This seminal study of the way in which persons
could be gotten to accede to unreasonable
requests has triggered a variety of studies that
have informed survey researchers about ways to
approach sensitive topics.

E. Gil, The California Child Abuse Reporting
Law: Issues and Answers for Professionals
(Publication No. 132 [10/86]), 1982.  Available
from the State of California Department of
Social Services, Office of Child Abuse
Prevention, 744 P Street, M.S. 9-100.
Sacramento, CA 95815.
This document provides many useful tips to the
professional who is subject to mandatory
reporting of child abuse in California.  Gil's
recommended wording to warn respondents that
confidentiality of survey or interview data is
not absolute is of particular interest.

J. Gilbert, Protecting Confidential Research
Information from Disclosure in Litigation, 
personal communication, Federal Judicial Center
Memo, July 7, 2000.
In this memo, legal intern Gilbert sets forth
the legal limits of protection to subpoenaed
data; of particular interest is his discussion
of the methods of legal discovery that can be
used to obtain data that have been sent outside
of the country.
E. Gray and J. Cosgrove, "Ethnocentric
Perceptions of Childrearing Practices in
Protective Services," Child Abuse and Neglect 9,
389-396 (1985).
Adding to the difficulty of defining child abuse
is the prevalence of major differences among
ethnic groups in punitiveness of childrearing
practices.

T. P. Johnson and R. W. Moore, "Gender
Interactions Between Interviewer and Survey
Respondents: Issues of Pornography and Community
Standards," Sex Roles 28, 5-6 (1993).
The authors did not find a gender effect in a
study of responses to a phone survey on use of
pornographic materials.

S. C. Kalichman, Mandated Reporting of Suspected
Child Abuse: Ethics, Law and Policy (Washington,
D.C.: APA, 1999).
Every State requires that human services
professionals report suspected child abuse. 
Kalichman offers an innovative model for making
the reporting decision.

M. Kim, "Poor Women Survey Poor Women: Feminist
Perspectives in Survey Research," Feminist
Economics 3, 99-117 (1997).
This article describes a highly qualitative and
collaborative approach to telephone surveys of
participants in job training programs.  The use
of poor women to interview poor women was highly
effective in creating rapport, reducing
interviewer bias, and facilitating the answering
of sensitive questions.

A. Kinsey, W. B. Pomeroy, C. E. Martin, and P.
H. Gebhard, Sexual Behavior in the Human Female
(Philadelphia: Saunders, 1953).
Kinsey and his associates pioneered the
development of survey techniques that enabled
them to elicit candid answers to highly
sensitive questions.

P. Kissinger, J. Rice, T. Farley, S. Trim, K.
Jewitt, V. Mangavio, and D. H. Martin,
"Application of Computer-Assisted Interviews to
Sexual Behavior Research," American Journal of
Epidemiology 149, 950-954 (1999).
The authors describe video-enhanced computer-
assisted, self-administered interviews, which
were shown to elicit more social undesirable
responses than face-to-face interviews.

R. A. Krueger, Focus Groups: A Practical Guide
for Applied Research (Newbury Park: Sage, 2nd
ed., 1994).
This handy guide and other works by Krueger have
good advice for researchers who want to conduct
focus groups.

J. A. Landsheer, P. G. van der Heijden, and G.
van Gils, "Trust and Understanding, Two
Psychological Aspects of Randomized Response,"
Quality and Quantity 33, 1-12 (1999).
This research established the importance of
trust and understanding of the method in
producing valid responses on socially
undesirable topics.

R. S. Laufer and M. Wolfe, "Privacy as a Concept
and a Social Issue: A Multidimensional
Developmental Theory," Journal of Social Issues
33, 44-87 (1977).
Laufer and Wolfe's theory of personal privacy
recognizes the manifold cultural, developmental,
and situational elements by which individuals
orchestrate their privacy.

J. T. Lesser and J. M. O'Reilly, "Mode of
Interview and Reporting of Sensitive Issues:
Design and Implementation of Audio Computer-
assisted Self-interviewing," NIDA Research
Monograph 167, 366-382 (1997).
The authors review various approaches to
interviewing people about sensitive issues. 
They include the implementation and results of
using audio-computer-assisted self-interviewing.

E. K. Levine, "Old People Are Not All Alike:
Social Class, Ethnicity/Race, and Sex Are Bases
for Important Differences," in J. E. Sieber,
ed., The Ethics of Social Research: Surveys and
Experiments (New York: Springer Verlag, 1982),
pp. 127-144.
This account traces the history of avoiding
research on the elderly, particularly elderly
women, details the kinds of issues that are not
raised in research publications, and shows how
many incorrect assumptions about elderly persons
have arisen out of poor sampling and assumptions
of homogeneity of this population.

M. Levine and A. Levine, Helping Children: A
Social History (New York: Oxford University
Press, 1983).
A history of the development of child welfare
reporting laws is presented.

L. E. Linden and D. J. Weiss, "An Empirical
Assessment of the Random Response Method of
Sensitive Data Collection," Journal of Social
Behavior and Personality 9, 823-836 (1994).
The authors studied sensitive aspects of
personal history in 285 undergraduates using
written questionnaires.  They found no
difference between direct and randomized
response methods of questioning.

P. A. Marshall, "Research Ethics in Applied
Anthropology," IRB: A Review of Human Subjects
Research 14, November-December, pp. 1-5 (1992).
Various problems arise when researchers apply
culturally insensitive approaches to non-Western
or non-mainstream cultures, and when researchers
apply federal regulations designed for
mainstream American culture elsewhere.  This
article describes the resulting dilemmas.

T. Makkai and I. McAllister, "Measuring Social
Indicators in Opinion Surveys: A Method to
Improve Accuracy on Sensitive Questions," Social
Indicators Research 27, 169-186 (1992).
The authors compare sealed booklet technique
with the face-to-face interview in terms of
respondent's willingness to answer sensitive
questions.

G. B. Melton, "Respecting Boundaries: Minors,
Privacy and Behavioral Research," in B. Stanley
and J. Sieber, eds., The Ethics of Research on
Children and Adolescents (Newbury Park: Sage,
1992), pp. 65-87.
The problems of protecting privacy and assuring
confidentiality of behavioral research on minors
are discussed.  The stages of development of
minor's sense of privacy are illustrated. 
Melton discusses uses and limits of Certificates
of Confidentiality.

G. B. Melton, R. J. Levine, G. P. Koocher, R.
Rosenthal, and W. Thompson, "Community
Consultation in Socially Sensitive Research:
Lessons from Clinical Trials on Treatments for
AIDS," American Psychologist 43, 573-581 (1988).
This classic article describes the process and
benefits of consultation between members of
vulnerable communities and researchers whose
intentions are regarded with suspicion, anger,
and plans for non-cooperation by those they seek
to study.

National Commission for the Protection of Human
Subjects of Biomedical and Behavioral Research,
The Belmont Report (Washington, D.C.: National
Commission for the Protection of Human Subjects
of Biomedical and Behavioral Research, 1979).
The Belmont Report sets forth the ethical
principles upon which the Federal Regulations of
Human Subjects are based.

M. T. Orne, "On the Social Psychology of the
Psychological Experiment: With Particular
Reference to Demand Characteristics and Their
Implications," American Psychologist 17, 776-783
(1962).
This classical essay provided an important
foundation for subsequent evaluation of the
demand characteristics of various social science
research activities.

P. Raghubir and G. Menon, "Asking Sensitive
Questions: The Effects of Type of Referent and
Frequency Wording in Counter-biasing Methods,"
Psychology & Marketing 13, 633-652 (1996).
The authors conducted two experiments that
tested the effects of counter-biasing methods on
respondent's willingness to admit to stigmatized
behaviors.

G. A. Sachs and C. K. Cassel, "Biomedical
Research Involving Older Human Subjects," Law,
Medicine and Health Care 18, 234-243 (1990).
This excellent article outlines special issues
arising in research on the elderly, and kinds of
safeguards and best practices advisable with
older populations.

J. E. Sieber, ed., Sharing Social Science Data:
Advantages and Challenges (Newbury Park: Sage,
1991).
This edited volume discusses a range of data
sharing arrangements and the attendant
challenges of protecting identities and
providing adequate documentation.  It includes
descriptions of a variety of innovative sharing
relationships.

J. E. Sieber, "Typically Unexamined
Communication Processes in Research," in B. H.
Stanley, J. E. Sieber, and G. B. Melton, eds.
Research Ethics: A Psychological Approach
(Lincoln: University of Nebraska Press, 1996).
This article specifies a range of meta-
communication processes that occur in research
and that may be deserving of research in
relation to ethical and methodological
questions.

J. E. Sieber and M. Saks, "A Census of Subject
Pool Characteristics and Policies," American
Psychologist 44, 1051-1063 (1989).
This is an illustration of an experiment within
a survey that examined the effects of anonymity
on response rate and frequency of acknowledging
unethical or illegal practices.

E. Singer, "Informed Consent: Consequences for
Response Rate and Response Quality in Social
Surveys," American Sociological Review 43, 144-
162 (1978).  
The author investigated the effects in face-to-
face interviews of more versus less information
about sensitive subject matter, of varied
assurances of confidentiality, and of requiring
or not requiring a signature to document
consent.  Varying information made no
difference, but was noticed if it failed to
mention pertinent elements of the study. 
Subjects were inaccurate in their perceptions of
how much confidentiality they had been promised. 
However perception that one had been given
absolute assurance of confidentiality was
associated with higher estimates of sensitive
behavior.  Subjects assigned to a condition in
which they were asked to sign a consent form
significantly more often refused to do so but
were willing to participate in the interview if
they didn't have to sign the consent form.

E. Singer, "Informed Consent in Surveys: A
Review of the Empirical Literature, "Journal of
Official Statistics, 9, 361-375, (1993).
This paper examines the effects of four elements
of consent: the content of the interview and
purpose of the research, assurances of
confidentiality or anonymity; active versus
passive consent, and voluntariness of
participation.  Of particular interest was the
finding that confidentiality promises have a
small effect on willingness to participate in
survey research.  Highly detailed promises are
counterproductive when the research questions
are not sensitive; presumably such detail raises
unwarranted concerns and suspicions.

E. Singer and M. R. Frankel, "Informed Consent
Procedures in Telephone Interviews," American
Sociological Review 47, June, pp. 416-427
(1982).
This paper reports an experiment with providing
varying amounts of information on the content
and purpose of the survey in the informed
consent.  Interestingly, the experimental
variables had little impact on the willingness
of respondents to be interviewed and the quality
of the interview.  However large variations in
response rate occurred among interviewers, with
experienced interviewers doing best with the
short consent statement and the inexperienced
ones doing best with the long statement.

E. Singer, R. M. Groves, and A. D. Corning,
"Differential Incentives: Beliefs about
Practices, Perceptions of Equity, and Effects on
Survey Participation," Public Opinion Quarterly
53, 251-260 (1999).
This study found that use of incentives to
convert refusals is perceived as inequitable but
that this does not effect the response rate of
cooperative subjects who know about this
practice.

E. Singer, H. Hippler, and N. Schwarz,
"Confidentiality Assurances in Surveys:
Reassurance or Threat?" International Journal of
Public Opinion Research 4, 256-268 (1992).
When non-threatening questions are accompanied
by elaborate assurances of confidentiality,
response rate is lowered.

E. Singer, N. Mathiowetz, and M. P. Couper, "The
Impact of Privacy and Confidentiality Concerns
on Survey Participation: The Case of the 1990
U.S. Census," Public Opinion Quarterly 57, 465-
482 (1993).
The impact of privacy and confidentiality
concerns are only slightly related to survey
response.

E. Singer, D. vonThurn, and E. Miller,
"Confidentiality Assurances and Response: A
Quantitative Review of the Experimental
Literature," Public Opinion Quarterly 59, 66-77
(1995).
Meta-analysis of 30 studies of the effect of
confidentiality assurances (verbal assurances,
anonymity, or use of randomized response method)
showed that assurances of all three kinds are
positively associated with response rate and
response quality, but only when sensitive
questions are asked.

E. Singer, N. Gebler, J. Van Hoewyk, T.
Raghunathan, and K. McGonagle, "The Effects of
Incentives on Response Rates in Face-to-Face and
Telephone Surveys," Journal of Official
Statistics 15, 217-230, (1999).
This experiment investigated the effects of
various kinds of incentives on response rate in
face-to-face and phone surveys.

T. W. Smith, "The Impact of the Presence of
Others on a Respondent's Answers to Questions,"
International Journal of Public Opinion Research
9, 33-47 (1997).
This study examines the effects of the presence
of spouses and children during interviews to
determine whether different responses are evoked
under these conditions.

A. L. Stanton, E. J. Burker, and D. Kershaw,
"Effects of Researcher Follow-up of Distressed
Subjects: Tradeoff Between Validity and Ethical
Responsibility?," Ethics & Behavior 1, 105-112
(1991).
This excellent experiment provides strong
evidence for the value of providing respondents
with useful information and referrals, and for
the importance of not seeking to intervene with
help that was not requested.

S. Sudman and N. M. Bradburn, Asking Questions.
(San Francisco: Jossey-Bass, 1982).
This is a highly practical and useful
introductory treatise on formulating and asking
questions of various types in survey research.

R. Thompson, "Developmental Changes in Research
Risk and Benefit: A Changing Calculus of
Concerns," in B. Stanley and J. Sieber, eds.,
Social Research on Children and Adolescents:
Ethical Issues (Newbury Park: Sage, 1982), pp.
31-64.
In contrast to the usual view that minors become
less vulnerable as they grow older, this chapter
presents a description of kinds of
vulnerabilities that arise through the
developmental sequence from early childhood to
adulthood, showing that there are forms of
vulnerability that increase with age through
adolescence.

R. Tourangeau and T. W. Smith, "Asking Sensitive
Questions: The Impact of Data Collection, Mode
of Question Format, and Question Context,"
Public Opinion Quarterly 80, 275-304 (1996).
This complex study examined the effects of three
kinds of computer-assisted interviewing, open-
versus closed-ended answer options, and
contextual variables.

A. D. Trice, "Informed Consent.  VII.  Biasing
of Sensitive Self-report Data by Both Consent
and Information," Journal of Social Behavior and
Personality 2, 369-374 (1987).
The author found that a significant number of
subjects refused to participate if required to
sign a consent form but were willing to
participate otherwise.

A. G. Turner, "What Subjects of Survey Research
Believe about Confidentiality," in J. E. Sieber,
ed., The Ethics of Social Research: Surveys and
Experiments (New York: Springer Verlag, 1982).
Turner summarizes a series of high-level studies
of what American populations, especially
minority populations, believe about survey
research.  Many see surveys as pointless since
they believe the government already knows
everything about them.  They do not trust
promises of confidentiality.  When individuals
find themselves in a position where they cannot
refuse to participate, they may be very careful
to say only those things that they believe will
not come back to haunt them, and are careful to
tell each survey taker the same story.

U. N. Umesh and R. A. Peterson, "A Critical
Evaluation of the Randomized Response Method:
Applications, Validation, and Research Agenda,"
Sociological Methods & Research 20, 104-118
(1991).
This article reviews recent applications of the
randomized response method, identifies new
issues being studied, and suggests future
research.

P. G. van der Heijden, G. van Gils, J. Bouts,
and J. J. Hox, "A Comparison of Randomized
Response, Computer-assisted Self Interview, and
Face-to-Face Direct Questioning: Eliciting
Sensitive Information in the Context of Welfare
and Unemployment Benefit," Sociological Methods
& Research 28, 505-537 (2000).
This is one of the few validation studies
conducted in which the respondents and
interviewers did not know that the researchers
knew about their welfare fraud.  Respondents in
the randomized response condition admitted more
acts of fraud than either the face-to-face
interviewed respondents or the computer-assisted
self-interviewed respondents.

M. L. Wax, "Gender and Age in Fieldwork and
Fieldwork Education," Social Problems 26, 509-
522 (1979).
Characteristics of the ethnographer influence
the talents he or she brings to the work, the
interaction likely to occur in the field, and
the way members of the community perceive the
ethnographer.

M. L. Wax, Testimony before the National
Bioethics Advisory Commission on Problems raised
by the Federal Regulations for Research in
Cultural Anthropology, Washington, D.C., April
6, 2000.

J. G. Weis, "Family Violence Research
Methodology and Design," in L. Ohlin and M.
Tonry, eds., Family Violence (Chicago:
University of Chicago Press, 1989), pp. 296-321.
This provides a comprehensive perspective on the
incidence of child abuse and the dependence of
reported incidence on definitional and research
criteria.

G. B. Willis, "The Use of the Psychological
Laboratory to Study Sensitive Survey Topics,"
NIDA Research Monograph 167, 416-438 (1997).
The author describes various cognitive
techniques for studying approaches to asking
sensitive questions in ways that produce
truthful answers, and offers recommendations for
improving survey design.
Appendix A.  State phone numbers for reporting
child maltreatment
Childhelp USA is a non-profit organization
dedicated to the prevention and treatment of
child abuse.  It assists States in establishing
guidelines to make their own laws to protect
abused and 
neglected children.  It has no authority to
intervene in individual child abuse and neglect
cases.  

Many States have a toll-free number to call to
report suspected abuse.  States with toll-free
child abuse reporting numbers are listed.  The
reporting party and the child who is allegedly
being abused must reside in the same State for
the following reporting numbers to be valid. 
When the reporting party resides in a different
State than the child, or for States not listed,
call Childhelp's National Child Abuse Hotline at
1-800-422-4453 or visit Childhelp's website at
http://www.childhelpusa.org.  Childhelp is not
involved in investigations by a government
agency.  Hotline counselors provide the State or
county reporting number to callers or provide
other referrals. 

This document is current as of September 12,
2000.
Arizona (800) 330-1822 
Arkansas (800) 482-5964 
Connecticut (800) 842-2288 
Delaware (800) 292-9582 
Florida (800) 962-2873 
Illinois (800) 252-2873 
Indiana (800) 562-2407 
Iowa (800) 362-2178 
Kansas (800) 922-5330
Kentucky (800) 752-6200 
Maine (800) 452-1999 
Massachusetts (800) 792-5200 
Michigan (800) 942-4357 
Mississippi (800) 222-8000 
Missouri (800) 392-3738 
Montana (800) 332-6100 
Nebraska (800) 652-1999 
Nevada (800) 992-5757 
New Hampshire (800) 894-5533 
New Jersey (800) 792-8610 
New Mexico (800) 432-2075 
New York (800) 342-3720 
North Carolina (800) 662-7030 
Oklahoma (800) 522-3511 
Oregon (800) 854-3508 
Pennsylvania (800) 932-0313 
Rhode Island (800) 742-4453 
Texas (800) 252-5400
Utah (800) 678-9399
Virginia (800) 552-7096 
Washington (800) 562-5624 
West Virginia (800) 352-6513

Appendix B.  Using focus groups

A focus group is a homogeneous group of 4 to 12
people who are invited to present their views on
a specific topic.  Group members are put at ease
(typically over a meal) in a gracious private
setting.  The moderator begins with a general
question on the topic and leads members to
discuss aspects about which information is
desired.  Often the moderator does not know just
how the participants would frame or discuss the
issue, and is open to unplanned turns in the
discussion.  A recorder or note-taker keeps
track of the ideas discussed and recaps them at
the end for further evaluation by the group.   

Focus groups motivate participants to think
deeply and develop new ideas.  While a survey or
interview generally only reveals which of
various predetermined alternatives is true for
individuals or gleans facts such as age, a focus
group can reveal entirely new insights never
contemplated before by the sponsor, the
moderator, or the participants.  A well-
organized focus group can take on a life of its
own with little apparent leadership from the
moderator.  However the moderator always has a
store of questions or probes that can be used to
get the discussion back on track if needed. 
Focus groups often go on longer than was
planned, with participants asking "When can we
come and discuss this again?"  The discussion is
usually highly involving and participants
typically view the discussion as a valuable and
rewarding experience.

Market researchers often pay focus group members
because their own interest is obviously
monetary, although the group may get excited
about the new product or service, and find
participation useful in its own right.  In most
other contexts, monetary incentives are
inappropriate.  Rather, researchers better
express  appreciation by giving participants a
little gift or a packet of useful information. 
Some focus groups are designed to explore the
possible value of new services, and the creation
of the needed services is the most rewarding
outcome of the focus group.  The traditional use
of focus groups in business is for market
research.  Homogeneous groups, representing
segments of the target market, are given an
opportunity to look over a proposed new product
or service (perhaps alternative versions of it)
to evaluate, discuss price point, use, and
report what they like and dislike about it. 
They might also discuss possible product
extensions and ways in which they would prefer
to receive or use the product.  The company uses
the information to develop, advertise, promote,
distribute, and merchandise the item.

Effective focus groups are carefully planned. 
It should include the following essential
elements:

1.  Know what questions you want answered and
how to probe group members in case the relevant
information is not readily forthcoming. 
Organize questions and probes starting with the
most general and introductory and concluding
with a summary question.  Reduce these to 5 to 7
very general questions.

2.  Define target population.  Who are the
people whose opinion you want to know?  
3.  Select groups of about 6 to 12 people,
keeping each group as homogeneous and compatible
as possible.  Do not mix genders, people of
different status, or people who would be guarded
around one another.  Groups may include friends
or strangers.

4.  Select good gatekeepers   people who will
help communicate to each group why their
participation is a good idea, recruit
individuals and groups, and find times and
places to meet.

5.  Effectively invite them.  The invitation may
be via more than one channel.  The gatekeeper
may do the initial recruitment, and follow up
with a letter describing all of the pertinent
information.  Offer appropriate incentive to
participate.

6.  Create a comfortable and private setting for
the focus group.

7.  Conduct the focus group, serve appropriate
food, and summarize.

8.  Organize responses around main questions or
emergent themes.  If more than one focus group
is conducted, identify main themes and
tangential themes.

9.  Prepare and disseminate report of findings.  


It is important that focus group members
perceive the moderator as neutral to the topic
of the group.  The idea is to get an entirely
unbiased, uninhibited response to questions.  If
a focus group member thinks a particular
product, service, or idea is "really lousy,"
they must feel free to say so.  A focus group is
of no value if its members feel constrained to
say nice things when they may feel otherwise. 
For example, a representative of the company
should not conduct a focus group evaluating a
company's new product line and a representative
of management should not conduct a focus group
that asks employees' evaluation of a proposed
new company policy.   

Focus groups are the method of choice when:

Exploring new ideas, such as proposed new
product designs, services, or activities. 
Because people do not have experience or
knowledge of these matters beforehand, they need
to discuss the idea before they can say how they
feel about it.
Exploring ideas germane to a specific group,
such as ideas about how to improve a group
activity that the group is engaged in, and about
which group discussion and evaluation is likely
to be more useful than individual evaluation.
Exploring how others conceptualize and talk
about an idea, including an old idea but one
that different groups conceptualize differently. 
Suppose, for example, a physical trainer wished
to consider offering exercise programs to elders
living in a retirement village.  What would they
like about such a program?  What are their
reservations?  How would they want to be
trained?  Focus groups could show whether there
is a market and how to reach it.
Seeking information from groups that will not
respond to a survey.  Literacy, time pressures,
ability to speak English, suspicion of
strangers, or cynicism about responding to
surveys or phone interviews are factors that may
necessitate use of focus groups.  Because of the
motivation built by gatekeepers and the
enthusiasm that is sustained by the group
setting -- plus the possibility to tailoring the
language, setting, and staffing to the
demography of the focus group members -- it is
possible to get thoughtful, creative, and
penetrating analysis from people who would not
even bother to respond or would respond
thoughtlessly to a survey.
A quick answer is needed.  Sometimes researchers
can assemble, conduct, and analyze results of
one or more focus groups within a week or two,
while a mailed survey is likely to take months.
One needs to know what to ask and how to ask it
on a survey.  A focus group may be an essential
prelude to developing and conducting a survey.

Surveys are useful when:

Seeking cut and dried answers to simple
questions.  If one knows how to ask the
questions in terms the respondents will
understand, and researchers can locate and
motivate a representative group of respondents,
surveys are most efficient tools.
Seeking demographic differences in response. 
Cross-tabulation of attitudinal and behavioral
responses with demographic variables shows who
thinks (or does) what.
One has a well defined target population and a
directory enabling one to randomly sample from
that population.  Random sampling assumes that
one has a list of all members of the population
from which to sample.  If the target population
is defined by a customer list or a membership
directory, and if one's relationship with that
population is such that they are motivated to
respond to your survey, a reasonable
approximation of a random sample might be
achieved and valid responses may be obtained.

Interviews are useful when the topic has the
characteristics of a focus group topic, but
when:

The respondents are busy people who have neither
the time nor inclination to fill out surveys or
attend focus groups.

The topic is sensitive and difficult for people
to discuss in a group setting or to respond to
in a survey.

Logistics of meeting are impossible to surmount. 
When respondents are widely disbursed
geographically or have incompatible schedules,
it may be necessary to hold individual
interviews rather than focus groups.

While interviews have the advantage that
persons' responses are individual and not
contaminated by those of other (focus group)
members, they have the disadvantage that they
are not enriched by the creative process of
group exchange and exploration.


th 6/26/01